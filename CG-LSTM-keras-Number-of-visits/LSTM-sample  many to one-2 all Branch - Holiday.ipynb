{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd,os\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sklearn\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from attention import Attention\n",
    "print('Scikit-Learn:',sklearn.__version__)\n",
    "# print('Keras:',keras.__version__)\n",
    "print('Numpy:',np.__version__)\n",
    "print('Pandas:',pd.__version__)\n",
    "print('Matplotlib:',matplotlib.__version__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def model_class(model_name, X_T, y_T, X_t, y_t, units, att_status):\n",
    "    model_input = Input(shape=(n_steps, n_features))\n",
    "    if 'base' in model_name:\n",
    "        x = LSTM(units, activation='tanh', return_sequences=att_status)(model_input)\n",
    "        if att_status==True:\n",
    "            x = Attention()(x)\n",
    "\n",
    "    elif 'stack' in model_name:\n",
    "        x = LSTM(units, activation='tanh', return_sequences=True)(model_input)\n",
    "        x = LSTM(units//2, activation='tanh', return_sequences=att_status)(x)\n",
    "        if att_status==True:\n",
    "            x = Attention()(x)\n",
    "    elif 'bidirect' in model_name:\n",
    "        x = Bidirectional(LSTM(units, activation='tanh', return_sequences=att_status))(model_input)\n",
    "        \n",
    "        if att_status==True:\n",
    "            x = LSTM(units//2, activation='tanh', return_sequences=True)(x)\n",
    "            x = Attention()(x)\n",
    "\n",
    "    x = Dense(1)(x)\n",
    "    model = Model(model_input, x)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    # model.summary()\n",
    "    print(f'----------start train {model_name}----------')\n",
    "    history = model.fit(X_T, y_T, epochs=100, validation_data=(X_t, y_t), verbose=0)\n",
    "    print(f'----------start test {model_name}----------')\n",
    "    trainPred = model.predict(X_T)\n",
    "    testPred = model.predict(X_t)\n",
    "    \n",
    "    return history, trainPred, testPred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y[0])\n",
    "\treturn np.array(X), np.array(y)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_features = 14\n",
    "n_steps = 30\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "def data_load(path_):\n",
    "    df = read_csv(path_)\n",
    "    # table csv datetime\n",
    "    df_col = df.columns\n",
    "    date_df = np.array(df[df_col[0]])\n",
    "    # table csv content date\n",
    "    df_n  = df[df_col[1::]]\n",
    "    temp = np.array( df_n['y'].copy()).reshape(-1,1)\n",
    "    temp = scaler.fit_transform(np.array(temp))\n",
    "    df_n = df_n.drop([\"y\"], axis=1)\n",
    "    df_n.insert(0,'y', temp)\n",
    "    # data subgroup train = train_len, test = total - train_len\n",
    "    train_len = len([i for i in date_df.flatten() if ('2015' in i)!=True])\n",
    "    Train_sub = df_n[:train_len]\n",
    "    Test_sub = df_n[train_len:]\n",
    "    # print(Test_sub)\n",
    "    X_T, y_T = split_sequence(np.array(Train_sub), 30)\n",
    "    X_t, y_t = split_sequence(np.array(Test_sub), 30)\n",
    "    print('Total Len = ',len(date_df.flatten()) ,'  Train Len = ',len(Train_sub), '  Test Len = ',len(Test_sub))\n",
    "    print(X_T.shape, y_T.shape, X_t.shape, y_t.shape, df_n.shape)\n",
    "    return X_T, y_T, X_t, y_t, df_n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# base_path = './dataset/'\n",
    "# data_stack=['Chiayi_holiday.csv']\n",
    "\n",
    "# X_T, y_T, X_t, y_t, _ = data_load(base_path+data_stack[0])\n",
    "# X_T[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "base_path = './dataset/'\n",
    "# data_stack=['Chiayi_holiday.csv']\n",
    "data_stack=['Chiayi_holiday.csv','Kaohsiung_holiday.csv','Keelung_holiday.csv','Linkou_holiday.csv','Taipei_holiday.csv','Yunlin_holiday.csv']\n",
    "model_list = ['base lstm', 'stack lstm', 'bidirect lstm']\n",
    "all_branch_train_pred=[]\n",
    "all_branch_test_pred=[]\n",
    "for path in data_stack:\n",
    "    print(f'Dataset: {path[:-4]}')\n",
    "    train_pred_list=[]\n",
    "    test_pred_list=[]\n",
    "    histroy_list=[]\n",
    "    X_T, y_T, X_t, y_t, _ = data_load(base_path+path)\n",
    "    for i in model_list:\n",
    "        att_status = False\n",
    "        # model_class def function = (model name, train data, train label, test data, test label, units number)\n",
    "        history, trainPred, testPred = model_class(i, X_T, y_T, X_t, y_t, 100, att_status)\n",
    "        train_pred_list.append(trainPred)\n",
    "        test_pred_list.append(testPred)\n",
    "        histroy_list.append(history)\n",
    "    all_branch_train_pred.append(train_pred_list)\n",
    "    all_branch_test_pred.append(test_pred_list)\n",
    "    \n",
    "    # plot history logs [train loss, test loss]\n",
    "    for j in range (len(histroy_list)):\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        plt.plot(histroy_list[j].history['loss'], label='train')\n",
    "        plt.plot(histroy_list[j].history['val_loss'], label='test')\n",
    "        plt.title(f'{model_list[j]}')\n",
    "        plt.legend()\n",
    "        if not os.path.exists(f'Results/{path[:-4]}'):\n",
    "            os.makedirs(f'Results/{path[:-4]}')\n",
    "        plt.savefig(f'Results/{path[:-4]}/ Results Plot test - {path[:-4]} Branch - {model_list[j]}.jpg')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# invert predictions\n",
    "def data_rescaler(input_data):\n",
    "    output_data = scaler.inverse_transform(input_data)\n",
    "    return output_data\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import math\n",
    "from keras import backend as K\n",
    "from keras.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(model_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# metric code\n",
    "# matplotlib.use('Agg')\n",
    "data_stack=['Chiayi_holiday.csv','Kaohsiung_holiday.csv','Keelung_holiday.csv','Linkou_holiday.csv','Taipei_holiday.csv','Yunlin_holiday.csv']\n",
    "metric_list = ['Train RMSE', 'Test RMSE', 'Train MAPE', 'Test MAPE', 'Train MAE', 'Test MAE']\n",
    "for idx, branch in enumerate(data_stack):\n",
    "    _, y_T, _, y_t , df_n= data_load(base_path + branch)\n",
    "    train_pred_list = all_branch_train_pred[idx]\n",
    "    test_pred_list = all_branch_test_pred[idx]\n",
    "    model_metric_stack=[]\n",
    "    for i in range(len(model_list)):\n",
    "        all_metric_stack = []\n",
    "        trainY = data_rescaler(y_T.reshape(-1,1))\n",
    "        testY = data_rescaler(y_t.reshape(-1,1))\n",
    "        trainPredict = data_rescaler(train_pred_list[i])\n",
    "        testPredict = data_rescaler(test_pred_list[i])\n",
    "        # print(trainY.shape, testY.shape, trainPredict.shape, testPredict.shape)\n",
    "        # RMSE\n",
    "        all_metric_stack.append((root_mean_squared_error(trainY[:,0], trainPredict[:,0])).numpy())\n",
    "        all_metric_stack.append((root_mean_squared_error(testY[:,0], testPredict[:,0])).numpy())\n",
    "        # MAPE\n",
    "        all_metric_stack.append((mean_absolute_percentage_error(trainY[:,0], trainPredict[:,0])).numpy())\n",
    "        all_metric_stack.append((mean_absolute_percentage_error(testY[:,0], testPredict[:,0])).numpy())\n",
    "        # MAE\n",
    "        all_metric_stack.append((mean_absolute_error(trainY[:,0], trainPredict[:,0])).numpy())\n",
    "        all_metric_stack.append((mean_absolute_error(testY[:,0], testPredict[:,0])).numpy())\n",
    "        model_metric_stack.append(all_metric_stack)\n",
    "\n",
    "        # shift train predictions for plotting\n",
    "        trainPredictPlot = (np.empty_like(df_n['y'])).reshape(-1,1)\n",
    "        trainPredictPlot[:, :] = np.nan\n",
    "        trainPredictPlot[30:len(trainPredict)+30, :] = trainPredict\n",
    "        # shift test predictions for plotting\n",
    "        testPredictPlot = (np.empty_like(df_n['y'])).reshape(-1,1)\n",
    "        testPredictPlot[:, :] = np.nan\n",
    "        testPredictPlot[len(trainPredict)+60:, :] = testPredict\n",
    "        # plot baseline and predictions\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.title(f'{model_list[i]}')\n",
    "        plt.plot(scaler.inverse_transform(np.array(df_n['y']).reshape(-1,1)), linewidth=1.5, label = 'Ground Turth')\n",
    "        plt.plot(trainPredictPlot, linewidth=1, label='Train')\n",
    "        plt.plot(testPredictPlot, linewidth=1, Label='Test')\n",
    "        plt.legend(fontsize=8)\n",
    "        if not os.path.exists(f'Results/{branch[:-4]}'):\n",
    "            os.makedirs(f'Results/{branch[:-4]}')\n",
    "        plt.savefig(f'Results/{branch[:-4]}/{branch[:-4]} - {model_list[i]} plot baseline and predictions test.jpg')\n",
    "        # plt.cla()\n",
    "        # plt.clf()\n",
    "        # plt.close()\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.axis('off')\n",
    "    plt.axis('tight')\n",
    "    plt.title(f'{branch[:-4]} ALL LSTM Model Results')\n",
    "    tab1 = plt.table(cellText=model_metric_stack, rowLabels = model_list, colLabels=metric_list, cellLoc='center',loc='center')\n",
    "    tab1.scale(1.5,1.5)\n",
    "    tab1.set_fontsize(14)\n",
    "    plt.savefig(f'Results/{branch[:-4]} Performance Table.jpg', bbox_inches=\"tight\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7af32e964d98b6710ab8f08f209ae1a00d70c2533a11eb9b4c59786de3aa55"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('lstm_tf2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "8f7af32e964d98b6710ab8f08f209ae1a00d70c2533a11eb9b4c59786de3aa55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
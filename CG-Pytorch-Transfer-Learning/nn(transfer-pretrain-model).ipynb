{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f44895c0210>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, os, random, math\n",
    "import torch, numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logs_realtime_reply:\n",
    "    def __init__(self):\n",
    "        self.avg_dice = 0.0\n",
    "        self.avg_loss=np.inf\n",
    "        self.avg_tn = 0\n",
    "        self.avg_fp = 0\n",
    "        self.avg_fn = 0\n",
    "        self.running_metic = {\"Loss\":0,\"Accuracy\":0, \"AUC\": 0}\n",
    "        self.end_epoch_metric = None\n",
    "    def metric_stack(self, inputs, targets, loss):\n",
    "        with torch.no_grad():\n",
    "            self.running_metic['Loss'] +=loss\n",
    "            # metric setting\n",
    "            SR = inputs.cpu().data.numpy()\n",
    "            GT = targets.cpu().data.numpy()\n",
    "            acc = metrics.accuracy_score(SR>0.5, GT)\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(GT, SR, pos_label=1)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            self.running_metic['Accuracy'] += round((acc), 5)\n",
    "            self.running_metic['AUC'] += round((auc), 5)\n",
    "    def mini_batch_reply(self, current_step, epoch, iter_len):\n",
    "        avg_reply_metric = {\"Loss\":None, \"Accuracy\": None, \"AUC\": None}\n",
    "        for j in avg_reply_metric:\n",
    "            avg_reply_metric[j] = round(self.running_metic[j]/int(current_step),5)\n",
    "        \n",
    "        if current_step ==iter_len:\n",
    "            self.end_epoch_metric = avg_reply_metric\n",
    "        return avg_reply_metric\n",
    "\n",
    "    def epoch_reply(self):\n",
    "        return self.end_epoch_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_classes, input_size):\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=input_size, out_features=10)\n",
    "        self.bn1 = nn.BatchNorm1d(10)\n",
    "        self.dt1 = nn.Dropout(0.25)\n",
    "        self.linear2 = nn.Linear(in_features=10, out_features=5)\n",
    "        self.bn2 = nn.BatchNorm1d(5)\n",
    "        self.dt2 = nn.Dropout(0.25)\n",
    "        self.linear3 = nn.Linear(in_features=5, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.linear1(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(self.linear2(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create():\n",
    "    model = MLP(num_classes=1, input_size=25)\n",
    "    model.initialize_weights()\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global best_tacc, best_tauc\n",
    "    get_logs_reply = logs_realtime_reply()\n",
    "    model.train()\n",
    "    # stream = tqdm(train_loader)\n",
    "   \n",
    "    for i, (text, label) in enumerate(train_loader, start=1):\n",
    "        text = text.to(device)\n",
    "        target = label.to(device)\n",
    "        # print(text)\n",
    "        output = model(text).squeeze(1)\n",
    "\n",
    "        # print(output)\n",
    "        # print(target)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        get_logs_reply.metric_stack(output, target, loss = round(loss.item(), 5))\n",
    "        avg_reply_metric = get_logs_reply.mini_batch_reply(i, epoch, len(train_loader))\n",
    "        avg_reply_metric['lr'] = optimizer.param_groups[0]['lr']\n",
    "        # stream.set_description(f\"Epoch: {epoch}. Train. {str(avg_reply_metric)}\")\n",
    "    avg_reply_metric = get_logs_reply.epoch_reply()\n",
    "    \n",
    "    for x in avg_reply_metric:\n",
    "        if x =='Accuracy' and avg_reply_metric[x] > best_tacc:\n",
    "            best_tacc = avg_reply_metric[x]\n",
    "            current_loss = avg_reply_metric['Loss']\n",
    "            save_ck_name = f'{ck_pth}/best - tacc - {project_name}.pt'\n",
    "            torch.save({\n",
    "                    'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), \n",
    "                    'loss':  current_loss,}, save_ck_name)\n",
    "            # print('save...', save_ck_name)\n",
    "        if x=='AUC' and avg_reply_metric[x]>best_tauc:\n",
    "            best_tauc = avg_reply_metric[x]\n",
    "            current_loss = avg_reply_metric['Loss']\n",
    "            best_ck_name = f'{ck_pth}/best - tauc - {project_name}.pt'\n",
    "            torch.save({\n",
    "                    'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), \n",
    "                    'loss':  current_loss,}, best_ck_name)\n",
    "            # print('save...', best_ck_name)\n",
    "        # print(avg_reply_metric)\n",
    "        writer.add_scalar(f'{x}/Train {x}', avg_reply_metric[x], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  train_valid_process_main(model, training_set, batch_size):\n",
    "    global best_tacc, best_tauc\n",
    "    # best_tloss = np.inf\n",
    "    best_tauc = 0.00\n",
    "    best_tacc = 0.00\n",
    "    # Subject Dataloader Building\n",
    "    train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "    for epoch in tqdm(range(1, params[\"epochs\"] + 1)):\n",
    "        train(train_loader, model, loss, optimizer, epoch)\n",
    "    print(\"Train\",\"Best accuracy:\", best_tacc, ' Best auc:', best_tauc)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LOC</th>\n",
       "      <th>SOFA total</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>D-dimer</th>\n",
       "      <th>Cortisol</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>SOFA score-Respiratory</th>\n",
       "      <th>Red Blood Cell</th>\n",
       "      <th>FDP</th>\n",
       "      <th>...</th>\n",
       "      <th>pH</th>\n",
       "      <th>Pulse rate</th>\n",
       "      <th>Highest SOFA score-cardiov</th>\n",
       "      <th>AaDO2</th>\n",
       "      <th>pCO2</th>\n",
       "      <th>SBE</th>\n",
       "      <th>ABE</th>\n",
       "      <th>FiO2</th>\n",
       "      <th>Total CO2</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467402</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>B996</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>B997</td>\n",
       "      <td>3</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.142458</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>B998</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.047486</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290873</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>B999</td>\n",
       "      <td>3</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.086592</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>B1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486097</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.369107</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  LOC  SOFA total  Albumin   D-dimer  Cortisol   Lactate  \\\n",
       "0       B1    2    0.523810      0.5  0.486097  0.189441  0.050279   \n",
       "1       B2    3    0.000000      0.5  0.486097  0.189441  0.016760   \n",
       "2       B3    2    0.000000      0.5  0.486097  0.189441  0.050279   \n",
       "3       B4    3    0.190476      0.5  0.486097  0.189441  0.050279   \n",
       "4       B5    1    0.047619      0.5  0.486097  0.189441  0.050279   \n",
       "..     ...  ...         ...      ...       ...       ...       ...   \n",
       "995   B996    3    0.000000      0.5  0.486097  0.189441  0.050279   \n",
       "996   B997    3    0.238095      0.5  0.486097  0.189441  0.142458   \n",
       "997   B998    2    0.333333      0.5  0.486097  0.189441  0.047486   \n",
       "998   B999    3    0.380952      0.5  0.486097  0.189441  0.086592   \n",
       "999  B1000    3    0.476190      0.0  0.486097  0.189441  0.050279   \n",
       "\n",
       "     SOFA score-Respiratory  Red Blood Cell       FDP  ...   pH  Pulse rate  \\\n",
       "0                  0.666667            0.08  0.652174  ...  0.0    0.595745   \n",
       "1                  0.666667            0.16  0.652174  ...  0.0    0.574468   \n",
       "2                  0.666667            0.16  0.652174  ...  0.0    0.356383   \n",
       "3                  0.666667            0.16  0.652174  ...  0.0    0.659574   \n",
       "4                  0.666667            0.16  0.652174  ...  0.0    0.452128   \n",
       "..                      ...             ...       ...  ...  ...         ...   \n",
       "995                0.666667            0.24  0.652174  ...  0.0    0.345745   \n",
       "996                0.666667            0.16  0.652174  ...  0.0    0.000000   \n",
       "997                0.666667            0.72  0.652174  ...  0.0    0.675532   \n",
       "998                0.333333            0.12  0.652174  ...  0.0    0.468085   \n",
       "999                1.000000            0.16  0.652174  ...  0.0    0.691489   \n",
       "\n",
       "     Highest SOFA score-cardiov     AaDO2      pCO2  SBE       ABE      FiO2  \\\n",
       "0                           0.0  0.369107  0.293333    0  0.477273  0.500000   \n",
       "1                           0.0  0.369107  0.293333    0  0.477273  0.230769   \n",
       "2                           0.0  0.369107  0.293333    0  0.477273  0.230769   \n",
       "3                           0.0  0.467402  0.506667    0  0.545455  0.453846   \n",
       "4                           0.0  0.369107  0.293333    0  0.477273  0.230769   \n",
       "..                          ...       ...       ...  ...       ...       ...   \n",
       "995                         0.0  0.369107  0.293333    0  0.477273  0.230769   \n",
       "996                         1.0  0.369107  0.293333    0  0.477273  0.230769   \n",
       "997                         0.0  0.290873  0.520000    0  0.681818  0.230769   \n",
       "998                         0.0  0.369107  0.293333    0  0.477273  0.384615   \n",
       "999                         1.0  0.369107  0.293333    0  0.477273  1.000000   \n",
       "\n",
       "     Total CO2  outcome  \n",
       "0     0.410256        0  \n",
       "1     0.410256        0  \n",
       "2     0.410256        0  \n",
       "3     0.512821        1  \n",
       "4     0.410256        0  \n",
       "..         ...      ...  \n",
       "995   0.410256        0  \n",
       "996   0.410256        1  \n",
       "997   0.666667        1  \n",
       "998   0.410256        0  \n",
       "999   0.410256        0  \n",
       "\n",
       "[1000 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('./xlsx/local_sepsis.csv')\n",
    "# data_df = pd.read_csv('./xlsx/original_555 sepsis dataset.csv')\n",
    "def dataloader(table):\n",
    "    for i in table:\n",
    "        if (i in ['ID','LOC','outcome'])==False:\n",
    "            # print(i)\n",
    "            cols_filter = [x for x in table[i] if math.isnan(float(x))==False ]\n",
    "            med = np.median(cols_filter)\n",
    "            table[i] = [med if math.isnan(float(x))==True else x for x in table[i]]\n",
    "            min_cols, max_cols =np.min(cols_filter), np.max(cols_filter)\n",
    "\n",
    "            normal = lambda x: (x - min_cols)/(max_cols - min_cols)\n",
    "            table[i] = [normal(x) for x in table[i]]\n",
    "            table[i] = [0 if math.isnan(float(x))==True else x for x in table[i]]\n",
    "    return table\n",
    "data_df = dataloader(data_df)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC: 1\n",
      "train  0:  54 1: 5\n",
      "valid 0:  18 1: 2\n",
      "(59, 25) (20, 25) (59,) (20,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Best accuracy: 0.91525  Best auc: 0.95556\n",
      "///-------Transfer Pretrain model-------///\n",
      "Accuracy: 0.9 \n",
      "AUC: 0.69444\n",
      "///-----------------Train &Test End-----------------///\n",
      "LOC: 2\n",
      "train  0:  86 1: 15\n",
      "valid 0:  29 1: 5\n",
      "(101, 25) (34, 25) (101,) (34,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Best accuracy: 1.0  Best auc: 1.0\n",
      "///-------Transfer Pretrain model-------///\n",
      "Accuracy: 0.85294 \n",
      "AUC: 0.66207\n",
      "///-----------------Train &Test End-----------------///\n",
      "LOC: 3\n",
      "train  0:  481 1: 108\n",
      "valid 0:  161 1: 36\n",
      "(589, 25) (197, 25) (589,) (197,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:06<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Best accuracy: 0.96719  Best auc: 0.9935\n",
      "///-------Transfer Pretrain model-------///\n",
      "Accuracy: 0.88325 \n",
      "AUC: 0.91494\n",
      "///-----------------Train &Test End-----------------///\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "# for i in range(50):\n",
    "    # seed = random.randint(10,100)\n",
    "for i in [1,2,3]:\n",
    "    data_df_LOC = data_df[data_df[\"LOC\"]==i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_df_LOC.drop(['outcome'],axis=1), data_df_LOC['outcome'], \n",
    "                                                                                                        test_size=0.25, stratify=list(data_df_LOC['outcome']), random_state=123) #seed = 42, 123\n",
    "    print(\"LOC:\", i)\n",
    "    print('train', ' 0: ', len(y_train)-sum(y_train),'1:',sum(y_train))\n",
    "    print('valid', '0: ', len(y_test)-sum(y_test), '1:',sum(y_test))\n",
    "\n",
    "    try:\n",
    "        X_train_ = np.array(X_train.drop(['ID','LOC'],axis=1))\n",
    "        X_test_ = np.array(X_test.drop(['ID','LOC'],axis=1))\n",
    "        y_train_ = np.array(y_train)\n",
    "        y_test_ = np.array(y_test)\n",
    "    except:\n",
    "        X_train_ = np.array(X_train.drop(['ID'],axis=1))\n",
    "        X_test_ = np.array(X_test.drop(['ID'],axis=1))\n",
    "        y_train_ = np.array(y_train)\n",
    "        y_test_ = np.array(y_test)\n",
    "    print(X_train_.shape, X_test_.shape, y_train_.shape, y_test_.shape)\n",
    "    if True: #model record\n",
    "        params = {\n",
    "            \"type\": \"Sepsis-Transfer\",\n",
    "            \"model\": 'MLP', #baseline = 'resnet18'\n",
    "            \"model_depth\": 3,\n",
    "            \"device\": \"cuda\",\n",
    "            \"opt\": \"Adam\",\n",
    "            \"lr\": 0.003, #baseline = 0.003\n",
    "            \"batch_size\": 64, #baseline resnet18 : 8\n",
    "            \"epochs\": 150,\n",
    "            \"fixing\": \"None\"\n",
    "            }\n",
    "    training_set = TensorDataset(torch.FloatTensor(X_train_), torch.FloatTensor(y_train_))\n",
    "\n",
    "    # checkpoint setting\n",
    "    project_name = f\"{params['type']} - {params['model']} - lr_{params['lr']} - CEL\"\n",
    "    project_folder = f\"2021.12.13.t1 - Sepsis - MLP - {params['type']} - Local{i}-Transfer Pretrain Model\"\n",
    "    ck_pth = f'./checkpoint/{project_folder}'\n",
    "    if os.path.exists(ck_pth)==False:\n",
    "        os.mkdir(ck_pth)\n",
    "    ck_name = project_name\n",
    "    path = f'./checkpoint/{project_folder}/{project_name}.txt'\n",
    "    f = open(path, 'w')\n",
    "    lines = params\n",
    "    f.writelines([f'{i} : {params[i]} \\n' for i in params])\n",
    "    f.close()\n",
    "    tensorboard_logdir = f'./logsdir/S2/ {project_folder} - {project_name}'\n",
    "    writer=SummaryWriter(tensorboard_logdir)\n",
    "    # checkpoint = torch.load('./checkpoint/2021.12.10.t1 - Sepsis - MLP - Sepsis-original/best - tauc - Sepsis-original - MLP3 - lr_0.003 - CEL.pt', map_location=torch.device(device))\n",
    "    model = model_create()\n",
    "    # model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    loss = torch.nn.BCELoss()\n",
    "    if params['opt']=='Adam':\n",
    "        optimizer = Adam(model.parameters(), lr=params['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'], weight_decay = 1e-4, momentum=0.9)\n",
    "    logs  = train_valid_process_main(model, training_set, params['batch_size'])\n",
    "    writer.close()\n",
    "    validation_set = TensorDataset(torch.FloatTensor(X_test_), torch.FloatTensor(y_test_))\n",
    "# Test\n",
    "    test_loader = DataLoader(validation_set, batch_size=len(validation_set), drop_last=False, shuffle=False)\n",
    "    checkpoint_path = f\"./checkpoint/{project_folder}/best - tauc - {params['type']} - MLP - lr_0.003 - CEL.pt\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "    model = model_create()\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to('cpu')\n",
    "    with torch.no_grad():\n",
    "        for i, (text, label) in enumerate(test_loader, start=1):\n",
    "            output = model(text.to('cpu'))\n",
    "            label = label\n",
    "        acc = metrics.accuracy_score(output>0.5, label)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(label, output, pos_label=1)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        print(\"///-------Transfer Pretrain model-------///\")\n",
    "        print(\"Accuracy:\", round(acc,5), \"\\nAUC:\", round(auc,5))\n",
    "        print(\"///-----------------Train &Test End-----------------///\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoint/2021.12.10.t1 - Sepsis - MLP - Sepsis-Transfer - Local1-Transfer Feature Extract/best - tauc - Sepsis-Transfer - MLP - lr_0.003 - CEL.pt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./checkpoint/2021.12.10.t1 - Sepsis - MLP - Sepsis-Transfer - Local1-Transfer Feature Extract/best - tauc - Sepsis-Transfer - MLP - lr_0.003 - CEL.pt'\n",
    "'./checkpoint/2021.12.10.t1 - Sepsis - MLP - Sepsis-Transfer - Local1-Transfer Feature Extract/best - tauc - Sepsis-Transfer - MLP - lr_0.003 - CEL.pt'\n",
    "# validation_set = TensorDataset(torch.FloatTensor(X_test_), torch.FloatTensor(y_test_))\n",
    "# test_loader = DataLoader(validation_set, batch_size=139, shuffle=False)\n",
    "# checkpoint_path = f'./checkpoint/{project_folder}/best - tauc - Sepsis-original - MLP3 - lr_0.003 - CEL.pt'\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "# model = model_create()\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.to('cpu')\n",
    "# with torch.no_grad():\n",
    "#     for i, (text, label) in enumerate(test_loader, start=1):\n",
    "#         output = model(text.to('cpu'))\n",
    "#         label = label\n",
    "#     acc = metrics.accuracy_score(output>0.5, label)\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(label, output, pos_label=1)\n",
    "#     auc = metrics.auc(fpr, tpr)\n",
    "#     print(\"///-------original model-------///\")\n",
    "#     print(\"Accuracy:\", round(acc,5), \"\\nAUC:\", round(auc,5))\n",
    "\n",
    "# # Dataset Scale\n",
    "# # train  0:  385 1: 31\n",
    "# # valid 0:  129 1: 10\n",
    "\n",
    "# # Test 結果\n",
    "# # 沒有初始化model weight\n",
    "# # Accuracy: 0.94964 \n",
    "# # AUC: 0.94109\n",
    "\n",
    "# # 有初始化model weight\n",
    "# # Accuracy: 0.92806 \n",
    "# # AUC: 0.89147"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cefeaee0cb99e52f47ecbf6a0fec4d636206690d7e9c62031f057a9471691d65"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('lstm_pyt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

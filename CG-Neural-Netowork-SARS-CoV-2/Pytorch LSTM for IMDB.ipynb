{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "# model_type = 'LSTM'\n",
    "model_type = 'MLP'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df = pd.read_csv('../lstm covid19/dataset2/SARS-CoV-2_2349_50up.csv')\n",
    "# df = pd.read_csv('../lstm covid19/dataset2/SARS-CoV-2_2262_100up_time.csv')\n",
    "# columnsNames = df.columns.values\n",
    "# columnsNames = [i+'_DNA' for i in columnsNames]\n",
    "# df.columns=columnsNames\n",
    "# df_text = df.rename(columns={'DNA_lineage':'lineage', 'DNA_time':'time'})\n",
    "# y_text = [i[0] for i in np.array(df_text)]\n",
    "# X_text = [i[1::] for i in np.array(df_text)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# label_text = np.unique(y_text, return_counts=False,return_index=False,return_inverse=False)\n",
    "# feature_text = np.unique(X_text, return_counts=False,return_index=False,return_inverse=False)\n",
    "# print(label_text, feature_text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd,os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "# model_type = 'LSTM'\n",
    "model_type = 'MLP'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# X_train, ans_train = np.load('../lstm covid19/dataset2/numpy_train_test_split_added time/X_train_100up_weeks.npy', allow_pickle=True), np.load('../lstm covid19/dataset2/numpy_train_test_split_added time/y_train_100up_weeks.npy', allow_pickle=True)\n",
    "\n",
    "# X_test, ans_test = np.load('../lstm covid19/dataset2/numpy_train_test_split_added time/X_test_100up_weeks.npy', allow_pickle=True), np.load('../lstm covid19/dataset2/numpy_train_test_split_added time/y_test_100up_weeks.npy', allow_pickle=True)\n",
    "# print(X_train.shape, ans_train.shape, X_test.shape, ans_test.shape)\n",
    "\n",
    "X_train, ans_train = np.load('./dataset3/X_train_class100_time.npy'), np.load('./dataset3/y_train_class100_time.npy', allow_pickle=True)\n",
    "\n",
    "X_test, ans_test = np.load('./dataset3/X_test_class100_time.npy', allow_pickle=True), np.load('./dataset3/y_test_class100_time.npy', allow_pickle=True)\n",
    "print(X_train.shape, ans_train.shape, X_test.shape, ans_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_train = np.unique(ans_train, return_counts=False,return_index=False,return_inverse=False)\n",
    "label_test = np.unique(ans_test, return_counts=False,return_index=False,return_inverse=False)\n",
    "print(label_train, label_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def label2value(data):\n",
    "    y = []\n",
    "    for i in data:\n",
    "        for id, j in enumerate(label_test):\n",
    "            if j==i:\n",
    "                y.append(id)\n",
    "    return np.array(y)\n",
    "y_train = label2value(ans_train)\n",
    "y_test = label2value(ans_test)\n",
    "print(y_train.shape, y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch.utils.data as data\n",
    "batch_size = 128\n",
    "train_zip = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "test_zip = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_zip, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=test_zip, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def accuracy(predictions, labels):\n",
    "    classes = torch.argmax(predictions, dim=1)\n",
    "    return torch.mean((classes == labels).float())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, class_n, Input_Size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=Input_Size,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(128, class_n)\n",
    "    def forward(self, x):\n",
    "        r_out, (h_c, h_h) = self.rnn(x, None)\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                # m.weight.data.normal_(0,0.01)\n",
    "                m.bias.data.zero_()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_classes, input_size):\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=input_size, out_features=1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dt1 = nn.Dropout(0.25)\n",
    "        self.linear2 = nn.Linear(in_features=1024, out_features=256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dt2 = nn.Dropout(0.25)\n",
    "        self.linear3 = nn.Linear(in_features=256, out_features= num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.linear1(x))\n",
    "        x = F.relu(x)\n",
    "        # x = self.dt1(x)\n",
    "        x = self.bn2(self.linear2(x))\n",
    "        x = F.relu(x)\n",
    "        # x = self.dt2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                # m.weight.data.normal_(0,0.01)\n",
    "                m.bias.data.zero_()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if hasattr(torch.cuda, 'empty_cache'):\n",
    "        torch.cuda.empty_cache()\n",
    "Input_Size = np.array(X_train).shape[1]\n",
    "min_valid_loss = np.inf\n",
    "if model_type=='LSTM':\n",
    "        model = RNN(max(y_train)+1, Input_Size).to(device)\n",
    "else:\n",
    "        model = MLP(max(y_train)+1, Input_Size).to(device)\n",
    "\n",
    "model.initialize_weights()\n",
    "\n",
    "LR = 0.0001\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Starting trainer\n",
    "for epoch in tqdm(range(1000)):\n",
    "        for step, (b_x, b_y) in enumerate(train_loader):\n",
    "            # Forward pass\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            # if torch.cuda.is_available():\n",
    "            #     if model_type=='LSTM':\n",
    "            #         b_x_, b_y_= (torch.unsqueeze(b_x, 1)).data.type(torch.FloatTensor).to(device), b_y.to(device)\n",
    "            #     else:\n",
    "            #         b_x_, b_y_= b_x.float().to(device), b_y.to(device)\n",
    "            # else:\n",
    "            #     if model_type=='LSTM':\n",
    "            #         b_x_, b_y_= (torch.unsqueeze(b_x, 1)).data.type(torch.FloatTensor).to(device), b_y.to(device)\n",
    "            #     else:\n",
    "            #         b_x_, b_y_= b_x.float().to(device), b_y.to(device)\n",
    "            if model_type=='LSTM':\n",
    "                b_x_, b_y_= (torch.unsqueeze(b_x, 1)).data.type(torch.FloatTensor).to(device), b_y.to(device)\n",
    "            else:\n",
    "                b_x_, b_y_= b_x.float().to(device), b_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            r_out = model(b_x_)\n",
    "            loss = loss_fun(r_out, b_y_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = loss.item()*b_x_.size(0)\n",
    "            del b_x_, b_y_\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0.0\n",
    "            model.eval()\n",
    "            for step, (b_x, b_y) in enumerate(valid_loader):\n",
    "                if model_type=='LSTM':\n",
    "                    b_x_, b_y_= (torch.unsqueeze(b_x, 1)).data.type(torch.FloatTensor).to(device), b_y.to(device)\n",
    "                else:\n",
    "                    b_x_, b_y_= b_x.float().to(device), b_y.to(device)\n",
    "                # if torch.cuda.is_available():\n",
    "                #     if model_type=='LSTM':\n",
    "                #         b_x_, b_y_= (torch.unsqueeze(b_x, 1)).data.type(torch.FloatTensor).to(device), b_y.to(device)\n",
    "                #     else:\n",
    "                #         b_x_, b_y_= b_x.float().to(device), b_y.to(device)\n",
    "                r_out = model(b_x_)\n",
    "                loss = loss_fun(r_out, b_y_)\n",
    "                valid_loss = loss.item()*b_x_.size(0)\n",
    "                del b_x_, b_y_\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            if min_valid_loss > valid_loss:\n",
    "                # print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "                min_valid_loss = valid_loss\n",
    "                \n",
    "                # Saving State Dict\n",
    "                torch.save({'state_dict': model.state_dict()}, f'./pth/{model_type}_saved_model_50_epoch-1000.pth.tar')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model loadings\n",
    "if model_type=='LSTM':\n",
    "        model = RNN(max(y_train)+1, Input_Size).to(device)\n",
    "else:\n",
    "        model = MLP(max(y_train)+1, Input_Size).to(device)\n",
    "# checkpoint = torch.load(f'./pth/{model_type}_saved_model_50_epoch-1000.pth.tar', map_location='cpu')\n",
    "checkpoint = torch.load(f'./pth/{model_type}_saved_model_50_epoch-1000.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DNA_list = ['-', 'A', 'C', 'G', 'N', 'T']\n",
    "print(X_train.shape[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn = pd.read_csv('../lstm covid19/feature_name.csv')\n",
    "\n",
    "fn = np.array(fn.values)\n",
    "fn = fn.flatten()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def index2text(value_data):\n",
    "#     text=[]\n",
    "#     for id1, n1 in enumerate(np.array(value_data)):\n",
    "#         for id2, n2 in enumerate(feature_text):\n",
    "#             if n1==id2:\n",
    "#                 add_ = str(n2)+'_'+str(id1)\n",
    "#                 text.append(add_)\n",
    "#     return text\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "shap.initjs()\n",
    "# class_n = 3 #0-7\n",
    "# for f_id, class_n in enumerate(label_train):\n",
    "f_id = 0\n",
    "class_n = label_test[f_id]\n",
    "batch = next(iter(valid_loader))\n",
    "value, ans = batch\n",
    "new_value = []\n",
    "# for id, i in enumerate(ans):\n",
    "    # if i==f_id:\n",
    "        # new_value.append(np.array(value[id]))\n",
    "\n",
    "# background = torch.tensor(new_value)\n",
    "background = value\n",
    "if model_type=='LSTM':\n",
    "    background_ex = (torch.unsqueeze(background, 1)).data.type(torch.FloatTensor)\n",
    "else:\n",
    "    background_ex = background.data.type(torch.FloatTensor)\n",
    "\n",
    "print('Test Data Shape ',value.shape)\n",
    "print('Extract Data Shape ', background.shape)\n",
    "print('Squeeze Data Shape ', background_ex.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    e = shap.DeepExplainer(model.cpu(), background_ex.cpu())\n",
    "shap_values = e.shap_values(background_ex.cpu())\n",
    "\n",
    "test_stack = []\n",
    "# for i in range(len(new_value)):\n",
    "#     temp = index2text(new_value[i])\n",
    "#     test_stack.append(temp)\n",
    "test_stack = np.array(value)\n",
    "# test_stack = np.array(test_stack)\n",
    "print('Ground Turth Data Shape ', test_stack.shape)\n",
    "if model_type=='LSTM':\n",
    "    shap_values_ = np.squeeze(np.array(shap_values),axis=-2)\n",
    "else:\n",
    "    shap_values_ = np.array(shap_values)\n",
    "\n",
    "print('Shap Values Shape ', shap_values_.shape)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f_id = 6\n",
    "class_n = label_test[f_id]\n",
    "print(shap_values_[f_id].shape, test_stack.shape)\n",
    "# for f_id, class_n in enumerate(label_train):\n",
    "shap.summary_plot(list(shap_values_), test_stack, plot_type=\"bar\", class_names=label_test, feature_names=fn, show=False)\n",
    "fig = plt.gcf()\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(14)\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Feature', fontsize=16)\n",
    "leg = ax.legend()\n",
    "\n",
    "plt.title(f'{model_type} Multiclass', fontsize=20)\n",
    "# plt.show()\n",
    "plt.rcParams[\"figure.figsize\"] = (10,20)\n",
    "plt.savefig(f'/ssd1/報告//Images//DNA/{model_type}//{model_type} multiclass-100-output.jpg', dpi=300)\n",
    "# shap.summary_plot(shap_values, X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.array(shap_values[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shap_values[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shap_values[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('lstm_pyt': conda)"
  },
  "interpreter": {
   "hash": "47ed0dbdec9901086886300defac8fc027ffa2cf340ed530b82da576181f4925"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, os, cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.executing_eagerly()\n",
    "from tensorflow import keras\n",
    "# Display\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 192\n",
    "depth = 32\n",
    "ALL_data_paths = [\n",
    "    os.path.join(os.getcwd(), \"is0001-is0154_mask_and_image/\", x)\n",
    "    for x in sorted(os.listdir(\"is0001-is0154_mask_and_image/\"))\n",
    "]\n",
    "print(\"MRI scans dataset: \" + str(len(ALL_data_paths)//2) + ' ALL')\n",
    "mask = []\n",
    "image = []\n",
    "for i in ALL_data_paths:\n",
    "    if 's.nii.gz' in i:\n",
    "        mask.append(i)\n",
    "    else:\n",
    "        image.append(i)\n",
    "print(len(mask), len(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from skimage import morphology\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "def normalize(volume, norm_type):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "#     min = np.min(volume)\n",
    "#     max = np.max(volume)\n",
    "#     volume[volume < min] = min\n",
    "#     volume[volume > max] = max\n",
    "#     volume = (volume - min) / (max - min)\n",
    "    if norm_type == 'zero_mean':\n",
    "        img_o = np.float32(volume.copy())\n",
    "        m = np.mean(img_o)\n",
    "        s = np.std(img_o)\n",
    "        volume = np.divide((img_o - m), s)\n",
    "    elif norm_type == 'div_by_max':\n",
    "        volume = np.divide(volume, np.percentile(volume,98))\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "def remove_noise_from_image(file_path):\n",
    "    image = nib.load(file_path)\n",
    "    if len(image.shape) == 4:\n",
    "        image = image.get_fdata()\n",
    "        width,height,queue,_ = image.shape\n",
    "        image = image[:,:,:,1]\n",
    "        image = np.reshape(image,(width,height,queue))\n",
    "    else:\n",
    "        image = image.get_fdata()\n",
    "        pass\n",
    "    shape = image.shape\n",
    "    for i in range(shape[2]):\n",
    "        image_2d = image[:, :, i]\n",
    "#         mask = image_2d <=20\n",
    "        mask = image_2d<=10\n",
    "        selem = morphology.disk(2)\n",
    "\n",
    "        segmentation = morphology.dilation(mask, selem)\n",
    "        labels, label_nb = ndimage.label(segmentation)\n",
    "\n",
    "        mask = labels ==0\n",
    "        mask = morphology.dilation(mask, selem)\n",
    "        mask = ndimage.morphology.binary_fill_holes(mask)\n",
    "        mask = morphology.dilation(mask, selem)\n",
    "\n",
    "        image[:, :, i] = mask * image_2d\n",
    "    image = normalize(image,\"div_by_max\")\n",
    "    return image\n",
    "\n",
    "def resize_volume(img,size,depth):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "        # Rotate img shape = (height, wight, depth)\n",
    "    for i in range(img.shape[2]):\n",
    "        img[:,:,i] = np.fliplr(np.flipud(img[:,:,i]))\n",
    "#     img = ndimage.rotate(img, 180, reshape=False, mode=\"nearest\")\n",
    "    img = ndimage.zoom(img, (size/current_height, size/current_width, 1), order=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scan(path):\n",
    "#     # Resize width, height and depth\n",
    "    volume = remove_noise_from_image(path)\n",
    "    volume = resize_volume(volume,size,depth)\n",
    "#   add only black background mri image\n",
    "    if volume.shape[2]!=depth:\n",
    "        add_black_num = depth - volume.shape[2]\n",
    "        volume = np.transpose(volume)\n",
    "        for i in range(add_black_num):\n",
    "            add_black_ = np.expand_dims(np.zeros((volume.shape[2],volume.shape[2])),axis=0)\n",
    "            volume = np.concatenate((volume, add_black_), axis = 0)\n",
    "        volume = np.transpose(volume)\n",
    "    volume = np.transpose(volume)\n",
    "    print(path)\n",
    "    print(f\"rebuild shape: {volume.shape}\")\n",
    "    return volume\n",
    "def mask_scan(path):\n",
    "#     print(path)\n",
    "    image = nib.load(path)\n",
    "    \n",
    "    if len(image.shape) == 4:\n",
    "        image = image.get_fdata()\n",
    "        width,height,queue,_ = image.shape\n",
    "        image = image[:,:,:,1]\n",
    "        image = np.reshape(image,(width,height,queue))\n",
    "    else:\n",
    "        image = image.get_fdata()\n",
    "        pass\n",
    "    image = resize_volume(image,size,depth)\n",
    "    shape = image.shape\n",
    "#   add only black background mri image\n",
    "    if image.shape[2]!=depth:\n",
    "        add_black_num = depth - image.shape[2]\n",
    "        image = np.transpose(image)\n",
    "        for i in range(add_black_num):\n",
    "            add_black_ = np.expand_dims(np.zeros((image.shape[2],image.shape[2])),axis=0)\n",
    "            image = np.concatenate((image, add_black_), axis = 0)\n",
    "        image = np.transpose(image)\n",
    "    image = np.transpose(image)\n",
    "    print(path)\n",
    "    print(f\"rebuild shape: {image.shape}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image_arr = np.array([process_scan(path) for path in image])\n",
    "# print(\"Done\")\n",
    "# mask_arr = np.array([mask_scan(path) for path in mask])\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('np_multi/image_arr_154', image_arr)\n",
    "# np.save('np_multi/mask_arr_154', mask_arr)\n",
    "image_arr = np.load('np_multi/image_arr_154.npy').astype(np.float32)\n",
    "mask_arr = np.load('np_multi/mask_arr_154.npy').astype(np.float32)\n",
    "print(image_arr.shape, mask_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask_arr.shape)\n",
    "# mask_arr = np.reshape(mask_arr,(86,32,192,192,1))\n",
    "plt.figure(figsize=(20,20))\n",
    "image_arr_ = image_arr[20]\n",
    "print(f\"pixel max = {np.max(image_arr_)} pixel min = {np.min(image_arr_)}\")\n",
    "for i in range(image_arr_.shape[0]-24):\n",
    "    plt.subplot(1,image_arr_.shape[0]-24,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image_arr_[i],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "mask_arr_ = mask_arr[20]\n",
    "print(f\"pixel max = {np.max(mask_arr_)} pixel min = {np.min(mask_arr_)}\")\n",
    "for i in range(mask_arr_.shape[0]-24):\n",
    "    plt.subplot(1,mask_arr_.shape[0]-24,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mask_arr_[i],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "image_arr = np.transpose(image_arr,(0,2,3,1))\n",
    "mask_arr = np.transpose(mask_arr,(0,2,3,1))\n",
    "\n",
    "image_arr = np.expand_dims(image_arr, axis=-1)\n",
    "mask_arr = np.expand_dims(mask_arr, axis=-1)\n",
    "print(image_arr.shape, mask_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "# seed = np.random.randint(200)\n",
    "seed = 987\n",
    "# random shuffle dataset\n",
    "# seed: cv1=1 cv2=123 cv3=456 cv4=789 cv5=987\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(image_arr) #image\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(mask_arr) #label\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(image_path)\n",
    "print(image_path[0])\n",
    "# mask_arr = to_categorical(mask_arr, 2 ,dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('np_multi/image_arr_cv2', image_arr)\n",
    "# np.save('np_multi/mask__arr_cv2', mask_arr)\n",
    "# np.save('np_multi/image_path_cv2', image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('np_multi/train_path_cv2_aug', image_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_train = image_path[:105]\n",
    "image_path_valid = image_path[105:]\n",
    "x_train = image_arr[:105]\n",
    "y_train = mask_arr[:105]\n",
    "x_val = image_arr[105:]\n",
    "y_val = mask_arr[105:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 cv1\n",
    "# /ssd1/cnn/Classification/3d_mask_classification/is0001-is0154_mask_and_image/is0088o.nii.gz\n",
    "# t1 cv2\n",
    "# /ssd1/cnn/Classification/3d_mask_classification/is0001-is0154_mask_and_image/is0005o.nii.gz\n",
    "# t1 cv3\n",
    "# /ssd1/cnn/Classification/3d_mask_classification/is0001-is0154_mask_and_image/is0047o.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv1\n",
    "# /ssd1/cnn/Classification/3d_mask_classification/is0001-is0100_mask_and_image/is0047o.nii.gz\n",
    "# cv2\n",
    "# /ssd1/cnn/Classification/3d_mask_classification/is0001-is0100_mask_and_image/is0076o.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs_train = x_train  # scale masks to [0, 1]\n",
    "imgs_valid = x_val# scale masks to [0, 1]\n",
    "imgs_mask_train = y_train # scale masks to [0, 1]\n",
    "imgs_mask_valid = y_val  # scale masks to [0, 1]\n",
    "print(len(image_path_train))\n",
    "print(imgs_train.shape)\n",
    "print(imgs_mask_train.shape)\n",
    "print(imgs_valid.shape)\n",
    "print(imgs_mask_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import interact\n",
    "# %matplotlib inline\n",
    "# def browse_image(images, labels):\n",
    "# #     shape = depth, height, wight\n",
    "#     n = images.shape[2]\n",
    "#     def view_image(i):\n",
    "        \n",
    "#         fig, ax = plt.subplots(nrows = 1, ncols = 2)\n",
    "#         ax[0].imshow(images[...,i], cmap = 'gray', interpolation = 'nearest')\n",
    "#         ax[0].set_title('X Slice: %s' %i)\n",
    "#         ax[1].imshow(labels[...,i], cmap = 'gray', interpolation = 'nearest')\n",
    "#         ax[1].set_title('Y Slice: %s' %i)\n",
    "#     interact(view_image, i = (0,n-1))\n",
    "# for i in range(imgs_train.ndim):\n",
    "#     browse_image(imgs_train[i,...,0], imgs_mask_train[i,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# for i in range(105):\n",
    "#     print(image_path_train[i])\n",
    "#     for j in range(32): \n",
    "#         if np.max(imgs_train[i][:,:,j])>0:\n",
    "            \n",
    "#             plt.figure(figsize=(12,12))\n",
    "#             plt.subplot(1,3,1)\n",
    "#             plt.imshow(np.squeeze(imgs_train[i][:,:,j]),cmap='gray')\n",
    "#             plt.title('Original Image')\n",
    "#             plt.subplot(1,3,2)\n",
    "#             plt.imshow(np.squeeze(imgs_mask_train[i][:,:,j]),cmap='gray')\n",
    "#             plt.title('Original Mask')\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmented import generator\n",
    "\n",
    "image_aug = generator.customImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "#             brightness_range=[0.5,1.0]\n",
    "            )\n",
    "\n",
    "mask_aug = generator.customImageDataGenerator(\n",
    "#             featurewise_center=True,\n",
    "#             featurewise_std_normalization=True,\n",
    "            rotation_range = 20,\n",
    "#             brightness_range=[0.5,1.5]\n",
    "            )\n",
    "\n",
    "image_aug_valid = generator.customImageDataGenerator(\n",
    "            )\n",
    "\n",
    "mask_aug_valid = generator.customImageDataGenerator(\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "\n",
    "X_train_datagen = image_aug.flow(imgs_train, batch_size=bs, seed=seed)\n",
    "Y_train_datagen = mask_aug.flow(imgs_mask_train, batch_size=bs, seed=seed)\n",
    "train_generator = zip(X_train_datagen, Y_train_datagen)\n",
    "\n",
    "X_valid_datagen = image_aug_valid.flow(imgs_valid, batch_size=bs, seed=seed)\n",
    "Y_valid_datagen = mask_aug_valid.flow(imgs_mask_valid, batch_size=bs, seed=seed)\n",
    "valid_generator = zip(X_valid_datagen, Y_valid_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "\n",
    "# def dice_coef_loss(y_true, y_pred):\n",
    "#     return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "# def tversky(y_true, y_pred):\n",
    "#     smooth=1\n",
    "#     alpha=0.7\n",
    "#     y_true_pos = K.flatten(y_true)\n",
    "#     y_pred_pos = K.flatten(y_pred)\n",
    "#     true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "#     false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
    "#     false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
    "#     return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "# def tversky_loss(y_true, y_pred):\n",
    "#     return 1 - tversky(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model_library.model_3d_denseunet import threed_unet\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.metrics import binary_crossentropy\n",
    "# fitting shape [[slice, w, h, c], class]\n",
    "model = threed_unet()\n",
    "learning_rate = 1e-5\n",
    "epoch = 150\n",
    "learning_decay_rate = learning_rate/epoch\n",
    "model.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, \n",
    "                             decay=learning_decay_rate, amsgrad=False), \n",
    "           loss=dice_p_bce, metrics=['accuracy',dice_coef])\n",
    "\n",
    "# model.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, \n",
    "#                              decay=learning_decay_rate, amsgrad=False), \n",
    "#            loss=general_dice_loss, metrics=['accuracy',general_dice])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "weight_dir = 'checkpoint'\n",
    "checkpoint_name = 'Unet_mri-best_cv5_aug_g-dl_dense_3d_154_t1'\n",
    "# model.load_weights(os.path.join(weight_dir,checkpoint_name+'.hdf5'))\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.mkdir(weight_dir)\n",
    "# checkpoint_name = 'Unet_mri-epoch:{epoch:02d}-loss:{loss:.2f}-Dice:{dice_coef:.4f}.hdf5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(os.path.join(weight_dir+'/metric_try3',f\"{checkpoint_name}.hdf5\"), \n",
    "                                   monitor='val_loss', mode=\"auto\", verbose=0, save_best_only=True)\n",
    "logdir = os.path.join(\"checkpoint/tensorboard2/\", checkpoint_name)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1,\n",
    "                                         embeddings_freq=0,embeddings_layer_names=None,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('-'*30,'\\nFitting model...\\n','-'*30)\n",
    "# history = model.fit(imgs_train, imgs_mask_train, batch_size=1, epochs=epoch, verbose=1, \n",
    "#                     shuffle=True, validation_data=(imgs_valid,imgs_mask_valid), \n",
    "#                     callbacks=[model_checkpoint,tensorboard_callback])\n",
    "\n",
    "history = model.fit(train_generator, epochs=epoch, \n",
    "                    verbose=0,\n",
    "                    steps_per_epoch= (len(imgs_train))//bs,\n",
    "                    shuffle=True, validation_data=valid_generator,\n",
    "                    validation_steps= len(imgs_valid)//bs,          \n",
    "                    callbacks=[model_checkpoint,tensorboard_callback])\n",
    "\n",
    "\n",
    "# history = model.fit(train_dataset, epochs=epoch, verbose=2, \n",
    "#                     shuffle=True, validation_data=validation_dataset, \n",
    "#                     callbacks=[model_checkpoint,tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*30)\n",
    "print('Loading and preprocessing test data...')\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "imgs_test = imgs_valid\n",
    "imgs_mask_test = imgs_mask_valid\n",
    "\n",
    "\n",
    "print('-'*30)\n",
    "print('Loading saved weights...')\n",
    "print('-'*30)\n",
    "\n",
    "model = threed_unet()\n",
    "weight_dir = 'checkpoint/metric_try3'\n",
    "checkpoint_name = checkpoint_name + '.hdf5'\n",
    "model.load_weights(os.path.join(weight_dir,checkpoint_name ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = model.predict(imgs_test, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for j in range(Results.shape[0]):\n",
    "    count = 1\n",
    "    for i in range(32):\n",
    "        if np.max(imgs_test[j][:,:,i])>0:\n",
    "            \n",
    "            plt.figure(figsize=(12,12))\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.imshow(np.squeeze(imgs_test[j][:,:,i]), cmap='gray')\n",
    "            plt.title('Original Image')\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.imshow(np.squeeze(imgs_mask_test[j][:,:,i]), cmap='gray')\n",
    "            plt.title('Original Mask')\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.imshow(np.squeeze(Results[j][:,:,i]) > .5, cmap='gray')\n",
    "\n",
    "            plt.title('Prediction')\n",
    "            plt.show()\n",
    "            print(image_path_valid[j][-14:]+\"_\"+str(count)+\"â†‘\")\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

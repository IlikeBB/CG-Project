{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, os, cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.executing_eagerly()\n",
    "from tensorflow import keras\n",
    "# Display\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI scans dataset: 130 ALL\n",
      "130 130\n"
     ]
    }
   ],
   "source": [
    "size = 192\n",
    "depth = 32\n",
    "ALL_data_paths = [\n",
    "    os.path.join(os.getcwd(), \"is0001-is0154_mask_and_image/\", x)\n",
    "    for x in sorted(os.listdir(\"is0001-is0154_mask_and_image/\"))\n",
    "]\n",
    "print(\"MRI scans dataset: \" + str(len(ALL_data_paths)//2) + ' ALL')\n",
    "mask = []\n",
    "image = []\n",
    "for i in ALL_data_paths:\n",
    "    if 's.nii.gz' in i:\n",
    "        mask.append(i)\n",
    "    else:\n",
    "        image.append(i)\n",
    "print(len(mask), len(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from skimage import morphology\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "def normalize(volume, norm_type):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "#     min = np.min(volume)\n",
    "#     max = np.max(volume)\n",
    "#     volume[volume < min] = min\n",
    "#     volume[volume > max] = max\n",
    "#     volume = (volume - min) / (max - min)\n",
    "    if norm_type == 'zero_mean':\n",
    "        img_o = np.float32(volume.copy())\n",
    "        m = np.mean(img_o)\n",
    "        s = np.std(img_o)\n",
    "        volume = np.divide((img_o - m), s)\n",
    "    elif norm_type == 'div_by_max':\n",
    "        volume = np.divide(volume, np.percentile(volume,98))\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "def remove_noise_from_image(file_path):\n",
    "    image = nib.load(file_path)\n",
    "    if len(image.shape) == 4:\n",
    "        image = image.get_fdata()\n",
    "        width,height,queue,_ = image.shape\n",
    "        image = image[:,:,:,1]\n",
    "        image = np.reshape(image,(width,height,queue))\n",
    "    else:\n",
    "        image = image.get_fdata()\n",
    "        pass\n",
    "    shape = image.shape\n",
    "    for i in range(shape[2]):\n",
    "        image_2d = image[:, :, i]\n",
    "#         mask = image_2d <=20\n",
    "        mask = image_2d<=10\n",
    "        selem = morphology.disk(2)\n",
    "\n",
    "        segmentation = morphology.dilation(mask, selem)\n",
    "        labels, label_nb = ndimage.label(segmentation)\n",
    "\n",
    "        mask = labels ==0\n",
    "        mask = morphology.dilation(mask, selem)\n",
    "        mask = ndimage.morphology.binary_fill_holes(mask)\n",
    "        mask = morphology.dilation(mask, selem)\n",
    "\n",
    "        image[:, :, i] = mask * image_2d\n",
    "    image = normalize(image,\"div_by_max\")\n",
    "    return image\n",
    "\n",
    "def resize_volume(img,size,depth):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "        # Rotate img shape = (height, wight, depth)\n",
    "    for i in range(img.shape[2]):\n",
    "        img[:,:,i] = np.fliplr(np.flipud(img[:,:,i]))\n",
    "#     img = ndimage.rotate(img, 180, reshape=False, mode=\"nearest\")\n",
    "    img = ndimage.zoom(img, (size/current_height, size/current_width, 1), order=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scan(path):\n",
    "#     # Resize width, height and depth\n",
    "    volume = remove_noise_from_image(path)\n",
    "    volume = resize_volume(volume,size,depth)\n",
    "#   add only black background mri image\n",
    "    if volume.shape[2]!=depth:\n",
    "        add_black_num = depth - volume.shape[2]\n",
    "        volume = np.transpose(volume)\n",
    "        for i in range(add_black_num):\n",
    "            add_black_ = np.expand_dims(np.zeros((volume.shape[2],volume.shape[2])),axis=0)\n",
    "            volume = np.concatenate((volume, add_black_), axis = 0)\n",
    "        volume = np.transpose(volume)\n",
    "    volume = np.transpose(volume)\n",
    "    print(path)\n",
    "    print(f\"rebuild shape: {volume.shape}\")\n",
    "    return volume\n",
    "def mask_scan(path):\n",
    "#     print(path)\n",
    "    image = nib.load(path)\n",
    "    \n",
    "    if len(image.shape) == 4:\n",
    "        image = image.get_fdata()\n",
    "        width,height,queue,_ = image.shape\n",
    "        image = image[:,:,:,1]\n",
    "        image = np.reshape(image,(width,height,queue))\n",
    "    else:\n",
    "        image = image.get_fdata()\n",
    "        pass\n",
    "    image = resize_volume(image,size,depth)\n",
    "    shape = image.shape\n",
    "#   add only black background mri image\n",
    "    if image.shape[2]!=depth:\n",
    "        add_black_num = depth - image.shape[2]\n",
    "        image = np.transpose(image)\n",
    "        for i in range(add_black_num):\n",
    "            add_black_ = np.expand_dims(np.zeros((image.shape[2],image.shape[2])),axis=0)\n",
    "            image = np.concatenate((image, add_black_), axis = 0)\n",
    "        image = np.transpose(image)\n",
    "    image = np.transpose(image)\n",
    "    print(path)\n",
    "    print(f\"rebuild shape: {image.shape}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154, 2)\n",
      "/ssd1/cnn/Classification/3d_mask_classification/is0001-is0154_mask_and_image/is0001o.nii.gz\n",
      "is0001s.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "MRI_csv = pd.read_csv('NIHSS.csv')\n",
    "save_list = [\"ID\",\"A/P\"]\n",
    "MRI_csv = np.array(MRI_csv[save_list])\n",
    "mask = np.array(mask)\n",
    "image = np.array(image)\n",
    "print(MRI_csv.shape)\n",
    "print(image[0])\n",
    "print(mask[0][-14:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_image_A=[]\n",
    "MRI_mask_A=[]\n",
    "MRI_image_P=[]\n",
    "MRI_mask_P=[]\n",
    "for i in (MRI_csv):\n",
    "    for j in image:\n",
    "        if i[0] in j[-14:]:\n",
    "            if i[1]=='A':\n",
    "                MRI_image_A.append(j)\n",
    "            elif i[1]=='P':\n",
    "                MRI_image_P.append(j)\n",
    "    for j in mask:\n",
    "        if i[0] in j[-14:]:\n",
    "            if i[1]=='A':\n",
    "                MRI_mask_A.append(j)\n",
    "            elif i[1]=='P':\n",
    "                MRI_mask_P.append(j)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image_arr_A = np.array([process_scan(path) for path in MRI_image_A])\n",
    "# print(\"Done\")\n",
    "# mask_arr_A = np.array([mask_scan(path) for path in MRI_mask_A])\n",
    "# print(\"Done\")\n",
    "# image_arr_P = np.array([process_scan(path) for path in MRI_image_P])\n",
    "# print(\"Done\")\n",
    "# mask_arr_P = np.array([mask_scan(path) for path in MRI_mask_P])\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mask_arr_P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 32, 192, 192) (81, 32, 192, 192) (49, 32, 192, 192) (49, 32, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "# np.save('np_multi/image_arr_A_154', image_arr_A)\n",
    "# np.save('np_multi/mask_arr_A_154', mask_arr_A)\n",
    "# np.save('np_multi/image_arr_P_154', image_arr_P)\n",
    "# np.save('np_multi/mask_arr_P_154', mask_arr_P)\n",
    "image_arr_A = np.load('np_multi/image_arr_A_154.npy').astype(np.float32)\n",
    "mask_arr_A = np.load('np_multi/mask_arr_A_154.npy').astype(np.float32)\n",
    "image_arr_P = np.load('np_multi/image_arr_P_154.npy').astype(np.float32)\n",
    "mask_arr_P = np.load('np_multi/mask_arr_P_154.npy').astype(np.float32)\n",
    "print(image_arr_A.shape, mask_arr_A.shape, image_arr_P.shape, mask_arr_P.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel max = 1.0 pixel min = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "mask_arr_ = mask_arr_P[20]\n",
    "print(f\"pixel max = {np.max(mask_arr_)} pixel min = {np.min(mask_arr_)}\")\n",
    "for i in range(mask_arr_.shape[0]-24):\n",
    "    plt.subplot(1,mask_arr_.shape[0]-24,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mask_arr_[i],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 192, 192, 32, 1) (81, 192, 192, 32, 1) (49, 192, 192, 32, 1) (49, 192, 192, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "image_arr_A = np.transpose(image_arr_A,(0,2,3,1))\n",
    "mask_arr_A = np.transpose(mask_arr_A,(0,2,3,1))\n",
    "image_arr_P = np.transpose(image_arr_P,(0,2,3,1))\n",
    "mask_arr_P = np.transpose(mask_arr_P,(0,2,3,1))\n",
    "\n",
    "image_arr_A = np.expand_dims(image_arr_A, axis=-1)\n",
    "mask_arr_A = np.expand_dims(mask_arr_A, axis=-1)\n",
    "image_arr_P = np.expand_dims(image_arr_P, axis=-1)\n",
    "mask_arr_P = np.expand_dims(mask_arr_P, axis=-1)\n",
    "print(image_arr_A.shape, mask_arr_A.shape, image_arr_P.shape, mask_arr_P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "# seed = np.random.randint(200)\n",
    "seed = 123\n",
    "# random shuffle dataset\n",
    "# seed: cv1=1 cv2=123 cv3=456 cv4=789 cv5=987\n",
    "def random_data_shuffle(data_arr):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data_arr) #image\n",
    "    return data_arr\n",
    "\n",
    "image_arr_A = random_data_shuffle(image_arr_A)\n",
    "mask_arr_A = random_data_shuffle(mask_arr_A)\n",
    "image_arr_P = random_data_shuffle(image_arr_P)\n",
    "mask_arr_P = random_data_shuffle(mask_arr_P)\n",
    "MRI_mask_A = random_data_shuffle(MRI_mask_A)\n",
    "MRI_mask_P = random_data_shuffle(MRI_mask_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr_P=mask_arr_P*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr_A = to_categorical(mask_arr_A, 3 ,dtype='uint8')\n",
    "mask_arr_P = to_categorical(mask_arr_P, 3 ,dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 192, 192, 32, 1) (81, 192, 192, 32, 3) (49, 192, 192, 32, 1) (49, 192, 192, 32, 3)\n",
      "64 39\n"
     ]
    }
   ],
   "source": [
    "A_size = int(image_arr_A.shape[0]*0.8)\n",
    "P_size = int(image_arr_P.shape[0]*0.8)\n",
    "print(image_arr_A.shape, mask_arr_A.shape, image_arr_P.shape, mask_arr_P.shape)\n",
    "print(A_size, P_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((image_arr_A[:A_size], image_arr_P[:P_size]), axis=0)\n",
    "y_train = np.concatenate((mask_arr_A[:A_size], mask_arr_P[:P_size]), axis=0)\n",
    "x_val = np.concatenate((image_arr_A[A_size:], image_arr_P[P_size:]), axis=0)\n",
    "y_val = np.concatenate((mask_arr_A[A_size:], mask_arr_P[P_size:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = np.concatenate((MRI_mask_A[:A_size], MRI_mask_P[:P_size]), axis=0)\n",
    "valid_path = np.concatenate((MRI_mask_A[A_size:], MRI_mask_P[P_size:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 192, 192, 32, 1)\n",
      "(103, 192, 192, 32, 3)\n",
      "(27, 192, 192, 32, 1)\n",
      "(27, 192, 192, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "imgs_train = x_train  # scale masks to [0, 1]\n",
    "imgs_valid = x_val# scale masks to [0, 1]\n",
    "imgs_mask_train = y_train # scale masks to [0, 1]\n",
    "imgs_mask_valid = y_val  # scale masks to [0, 1]\n",
    "print(imgs_train.shape)\n",
    "print(imgs_mask_train.shape)\n",
    "print(imgs_valid.shape)\n",
    "print(imgs_mask_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmented import generator\n",
    "\n",
    "image_aug = generator.customImageDataGenerator(\n",
    "            rotation_range = 20,\n",
    "#             horizontal_flip=True\n",
    "            \n",
    "#             brightness_range=[0.5,1.0]\n",
    "            )\n",
    "\n",
    "mask_aug = generator.customImageDataGenerator(\n",
    "#             featurewise_center=True,\n",
    "#             featurewise_std_normalization=True,\n",
    "            rotation_range = 20,\n",
    "#             horizontal_flip=True\n",
    "#             brightness_range=[0.5,1.5]\n",
    "            )\n",
    "\n",
    "image_aug_valid = generator.customImageDataGenerator(\n",
    "            )\n",
    "\n",
    "mask_aug_valid = generator.customImageDataGenerator(\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "\n",
    "X_train_datagen = image_aug.flow(imgs_train, batch_size=bs, seed=seed)\n",
    "Y_train_datagen = mask_aug.flow(imgs_mask_train, batch_size=bs, seed=seed)\n",
    "train_generator = zip(X_train_datagen, Y_train_datagen)\n",
    "\n",
    "X_valid_datagen = image_aug_valid.flow(imgs_valid, batch_size=bs, seed=seed)\n",
    "Y_valid_datagen = mask_aug_valid.flow(imgs_mask_valid, batch_size=bs, seed=seed)\n",
    "valid_generator = zip(X_valid_datagen, Y_valid_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 0\n",
    "    intersection = K.sum(y_true * y_pred, axis=(1,2,3))\n",
    "    union = K.sum(y_true, axis=(1,2,3)) + K.sum(y_pred, axis=(1,2,3))\n",
    "    sample_dices=(2. * intersection + smooth) / (union + smooth) #一维数组 为各个类别的dice\n",
    "    dices=K.mean(sample_dices,axis=0)\n",
    "    dice_coef=K.mean(dices)\n",
    "    return dice_coef\n",
    "\n",
    "def dice_coef_loss(y_true,y_pred):\n",
    "    dice_loss = 1-1-dice_coef(y_true,y_pred)\n",
    "    return dice_loss\n",
    "\n",
    "def tversky_coef(y_true, y_pred):\n",
    "    alpha = 0.2\n",
    "    beta = 0.8\n",
    "    p0 = y_pred  # proba that voxels are class i\n",
    "    p1 = 1 - y_pred  # proba that voxels are not class i\n",
    "    g0 = y_true\n",
    "    g1 = 1 - y_true\n",
    "\n",
    "    # 求得每个sample的每个类的dice\n",
    "    num = K.sum(p0 * g0, axis=( 1, 2, 3))\n",
    "    den = num + alpha * K.sum(p0 * g1,axis= ( 1, 2, 3)) + beta * K.sum(p1 * g0, axis=( 1, 2, 3))\n",
    "    T = num / den  #[batch_size,class_num]\n",
    "\n",
    "    # 求得每个类的dice\n",
    "    dices=K.mean(T,axis=0) #[class_num]\n",
    "\n",
    "    return K.mean(dices)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true,y_pred):\n",
    "    return 1-tversky_coef(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model_library.model_3d_denseunet_multi import threed_unet\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "# fitting shape [[slice, w, h, c], class]\n",
    "model = threed_unet()\n",
    "learning_rate = 1e-5\n",
    "epoch = 150\n",
    "learning_decay_rate = learning_rate/epoch\n",
    "model.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, \n",
    "                             decay=learning_decay_rate, amsgrad=False), \n",
    "           loss=tversky_loss, metrics=['accuracy',tversky_coef])\n",
    "\n",
    "# model.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, \n",
    "#                              decay=learning_decay_rate, amsgrad=False), \n",
    "#            loss=general_dice_loss, metrics=['accuracy',general_dice])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "weight_dir = 'checkpoint'\n",
    "checkpoint_name = 'mcUnet_mri-best_cv2_aug_tversky_dense_3d_154_t1'\n",
    "# model.load_weights(os.path.join(weight_dir,checkpoint_name+'.hdf5'))\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.mkdir(weight_dir)\n",
    "# checkpoint_name = 'Unet_mri-epoch:{epoch:02d}-loss:{loss:.2f}-Dice:{dice_coef:.4f}.hdf5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(os.path.join(weight_dir+'/metric_try4',f\"{checkpoint_name}.hdf5\"), \n",
    "                                   monitor='val_loss', mode=\"auto\", verbose=0, save_best_only=True)\n",
    "logdir = os.path.join(\"checkpoint/tensorboard3/\", checkpoint_name)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1,\n",
    "                                         embeddings_freq=0,embeddings_layer_names=None,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ \n",
      "Fitting model...\n",
      " ------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*30,'\\nFitting model...\\n','-'*30)\n",
    "# history = model.fit(imgs_train, imgs_mask_train, batch_size=1, epochs=epoch, verbose=1, \n",
    "#                     shuffle=True, validation_data=(imgs_valid,imgs_mask_valid), \n",
    "#                     callbacks=[model_checkpoint,tensorboard_callback])\n",
    "history = model.fit(train_generator, epochs=epoch, \n",
    "                    verbose=0,\n",
    "                    steps_per_epoch= (len(imgs_train))//bs,\n",
    "                    shuffle=True, validation_data=valid_generator,\n",
    "                    validation_steps= len(imgs_valid)//bs,          \n",
    "                    callbacks=[model_checkpoint,tensorboard_callback])\n",
    "\n",
    "print(\"Training Done\")\n",
    "# history = model.fit(train_dataset, epochs=epoch, verbose=2, \n",
    "#                     shuffle=True, validation_data=validation_dataset, \n",
    "#                     callbacks=[model_checkpoint,tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*30)\n",
    "print('Loading and preprocessing test data...')\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "imgs_test = imgs_valid\n",
    "imgs_mask_test = imgs_mask_valid\n",
    "\n",
    "\n",
    "print('-'*30)\n",
    "print('Loading saved weights...')\n",
    "print('-'*30)\n",
    "\n",
    "model = threed_unet()\n",
    "weight_dir = 'checkpoint/metric_try4'\n",
    "checkpoint_name = checkpoint_name + '.hdf5'\n",
    "model.load_weights(os.path.join(weight_dir,checkpoint_name ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "pred_result = Results\n",
    "print(pred_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unlabelled = [0,0,0]\n",
    "anterior = [255,255,0] #yellow\n",
    "posterior = [0,255,255] #sky blue\n",
    "COLOR_DICT = np.array([Unlabelled, anterior, posterior])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def color_change(one_slice_array):\n",
    "    transpose =  np.transpose(one_slice_array,(2,0,1,3))\n",
    "    for i in range(transpose.shape[0]):\n",
    "        temp_32 = transpose[i]\n",
    "        for j in range(temp_32.shape[0]):\n",
    "            for k in range(temp_32.shape[1]):\n",
    "                index_of_class = np.argmax(temp_32[j,k])\n",
    "                temp_32[j,k] = COLOR_DICT[index_of_class]\n",
    "        transpose[i] = temp_32\n",
    "    ready_result = np.transpose(transpose, (1,2,0,3))\n",
    "    return ready_result\n",
    "\n",
    "\n",
    "for i in tqdm(range(pred_result.shape[0])):\n",
    "    pred_result[i] = color_change(pred_result[i])\n",
    "    pred_result[i] = pred_result[i].astype(np.uint8)\n",
    "print('Done')\n",
    "\n",
    "for i in tqdm(range(imgs_mask_test.shape[0])):\n",
    "    imgs_mask_test[i] = color_change(imgs_mask_test[i])\n",
    "    imgs_mask_test[i] = imgs_mask_test[i].astype(np.uint8)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_result = np.transpose(pred_result,(0,3,1,2,4))\n",
    "trans_mask = np.transpose(imgs_mask_test,(0,3,1,2,4))\n",
    "trans_imgs = np.transpose(imgs_test,(0,3,1,2,4))\n",
    "def plt_show(image_, mask_, mask_i,path_):\n",
    "    for i in range(image_.shape[0]):\n",
    "        \n",
    "        if np.max(image_[i])>0:\n",
    "            print(path_)\n",
    "            plt.figure(figsize=(12,12))\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.imshow(np.squeeze(image_[i]), cmap='gray')\n",
    "            plt.title('Original Image')\n",
    "            plt.subplot(1,3,2)\n",
    "            mask = mask_[i].astype(np.uint8)\n",
    "            plt.imshow(mask, interpolation='nearest',vmin=0,vmax=255)\n",
    "            plt.title('Original Mask')\n",
    "            plt.subplot(1,3,3)\n",
    "            pred = mask_i[i].astype(np.uint8)\n",
    "            plt.imshow(pred, interpolation='nearest',vmin=0,vmax=255)\n",
    "            plt.title('Prediction')\n",
    "            plt.show()\n",
    "for j in range(trans_result.shape[0]):\n",
    "    plt_show(trans_imgs[j],trans_mask[j],trans_result[j],valid_path[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f833cd45130>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, os, random, math\n",
    "import torch, numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logs_realtime_reply:\n",
    "    def __init__(self):\n",
    "        self.avg_dice = 0.0\n",
    "        self.avg_loss=np.inf\n",
    "        self.avg_tn = 0\n",
    "        self.avg_fp = 0\n",
    "        self.avg_fn = 0\n",
    "        # self.running_metic = {\"Loss\":0, \"TP\":0, \"FP\":0, \"FN\": 0, \"Spec\": 0, \"Sens\": 0}\n",
    "        # self.running_metic = {\"Loss\":0, \"Accuracy\":0, \"Spec\": 0, \"Sens\": 0, \"AUC\": 0}\n",
    "        self.running_metic = {\"Loss\":0,\"Accuracy\":0, \"AUC\": 0}\n",
    "        self.end_epoch_metric = None\n",
    "    def metric_stack(self, inputs, targets, loss):\n",
    "        with torch.no_grad():\n",
    "            self.running_metic['Loss'] +=loss\n",
    "            # metric setting\n",
    "            SR = inputs.cpu().data.numpy()\n",
    "            GT = targets.cpu().data.numpy()\n",
    "            # print(\"SR\", SR)\n",
    "            # print(\"GT\", GT)\n",
    "            acc = metrics.accuracy_score(SR>0.5, GT)\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(GT, SR, pos_label=1)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            self.running_metic['Accuracy'] += round((acc), 5)\n",
    "            self.running_metic['AUC'] += round((auc), 5)\n",
    "    def mini_batch_reply(self, current_step, epoch, iter_len):\n",
    "        # avg_reply_metric = {\"Loss\":None, \"TP\":None, \"FP\":None, \"FN\": None, \"Spec\": None, \"Sens\": None}\n",
    "        avg_reply_metric = {\"Loss\":None, \"Accuracy\": None, \"AUC\": None}\n",
    "        # avg_reply_metric = {\"Loss\":None, \"Accuracy\": None,\"Spec\": None, \"Sens\": None, \"AUC\": None}\n",
    "        for j in avg_reply_metric:\n",
    "            avg_reply_metric[j] = round(self.running_metic[j]/int(current_step),5)\n",
    "        \n",
    "        if current_step ==iter_len:\n",
    "            self.end_epoch_metric = avg_reply_metric\n",
    "        return avg_reply_metric\n",
    "\n",
    "    def epoch_reply(self):\n",
    "        return self.end_epoch_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_classes, input_size):\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=input_size, out_features=10)\n",
    "        self.bn1 = nn.BatchNorm1d(10)\n",
    "        self.dt1 = nn.Dropout(0.25)\n",
    "        self.linear2 = nn.Linear(in_features=10, out_features=5)\n",
    "        self.bn2 = nn.BatchNorm1d(5)\n",
    "        self.dt2 = nn.Dropout(0.25)\n",
    "        self.linear3 = nn.Linear(in_features=5, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.linear1(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(self.linear2(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create():\n",
    "    model = MLP(num_classes=1, input_size=25)\n",
    "    model.initialize_weights()\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global best_tacc, best_tauc\n",
    "    get_logs_reply = logs_realtime_reply()\n",
    "    model.train()\n",
    "    # stream = tqdm(train_loader)\n",
    "   \n",
    "    for i, (text, label) in enumerate(train_loader, start=1):\n",
    "        images = text.to(device)\n",
    "        target = label.to(device)\n",
    "        output = model(images).squeeze(1)\n",
    "        # print(output)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        get_logs_reply.metric_stack(output, target, loss = round(loss.item(), 5))\n",
    "        avg_reply_metric = get_logs_reply.mini_batch_reply(i, epoch, len(train_loader))\n",
    "        avg_reply_metric['lr'] = optimizer.param_groups[0]['lr']\n",
    "        # stream.set_description(f\"Epoch: {epoch}. Train. {str(avg_reply_metric)}\")\n",
    "    avg_reply_metric = get_logs_reply.epoch_reply()\n",
    "    \n",
    "    for x in avg_reply_metric:\n",
    "        if x =='Accuracy' and avg_reply_metric[x] > best_tacc:\n",
    "            best_tacc = avg_reply_metric[x]\n",
    "            current_loss = avg_reply_metric['Loss']\n",
    "            save_ck_name = f'{ck_pth}/best - tacc - {project_name}.pt'\n",
    "            torch.save({\n",
    "                    'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), \n",
    "                    'loss':  current_loss,}, save_ck_name)\n",
    "            # print('save...', save_ck_name)\n",
    "        if x=='AUC' and avg_reply_metric[x]>best_tauc:\n",
    "            best_tauc = avg_reply_metric[x]\n",
    "            current_loss = avg_reply_metric['Loss']\n",
    "            best_ck_name = f'{ck_pth}/best - tauc - {project_name}.pt'\n",
    "            torch.save({\n",
    "                    'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), \n",
    "                    'loss':  current_loss,}, best_ck_name)\n",
    "            # print('save...', best_ck_name)\n",
    "        # print(avg_reply_metric)\n",
    "        writer.add_scalar(f'{x}/Train {x}', avg_reply_metric[x], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  train_valid_process_main(model, training_set, batch_size):\n",
    "    global best_tacc, best_tauc\n",
    "    # best_tloss = np.inf\n",
    "    best_tauc = 0.00\n",
    "    best_tacc = 0.00\n",
    "    # Subject Dataloader Building\n",
    "    train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "    for epoch in tqdm(range(1, params[\"epochs\"] + 1)):\n",
    "        train(train_loader, model, loss, optimizer, epoch)\n",
    "    print(\"Train\",\"Best accuracy:\", best_tacc, ' Best auc:', best_tauc)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = pd.read_csv('./xlsx/local_sepsis.csv')\n",
    "data_df = pd.read_csv('./xlsx/original_555 sepsis dataset.csv')\n",
    "def dataloader(table):\n",
    "    for i in table:\n",
    "        if (i in ['ID','LOC','outcome'])==False:\n",
    "            cols_filter = [x for x in table[i] if math.isnan(float(x))==False ]\n",
    "            med = np.median(cols_filter)\n",
    "            table[i] = [med if math.isnan(float(x))==True else x for x in table[i] ]\n",
    "            min_cols, max_cols =np.min(cols_filter), np.max(cols_filter)\n",
    "            normal = lambda x: (x - min_cols)/(max_cols - min_cols)\n",
    "            table[i] = [normal(x) for x in table[i]]\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  0:  385 1: 31\n",
      "valid 0:  129 1: 10\n",
      "(416, 25) (139, 25) (416,) (139,)\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "# for i in range(50):\n",
    "    # seed = random.randint(10,100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df.drop(['outcome'],axis=1), data_df['outcome'], \n",
    "                                                                                                    test_size=0.25, stratify=list(data_df['outcome']), random_state=123) #seed = 42, 123\n",
    "X_train = dataloader(X_train)\n",
    "X_test = dataloader(X_test)\n",
    "print('train', ' 0: ', len(y_train)-sum(y_train),'1:',sum(y_train))\n",
    "print('valid', '0: ', len(y_test)-sum(y_test), '1:',sum(y_test))\n",
    "\n",
    "try:\n",
    "    X_train_ = np.array(X_train.drop(['ID','LOC'],axis=1))\n",
    "    X_test_ = np.array(X_test.drop(['ID','LOC'],axis=1))\n",
    "    y_train_ = np.array(y_train)\n",
    "    y_test_ = np.array(y_test)\n",
    "except:\n",
    "    X_train_ = np.array(X_train.drop(['ID'],axis=1))\n",
    "    X_test_ = np.array(X_test.drop(['ID'],axis=1))\n",
    "    y_train_ = np.array(y_train)\n",
    "    y_test_ = np.array(y_test)\n",
    "print(X_train_.shape, X_test_.shape, y_train_.shape, y_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:02<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Best accuracy: 0.9336  Best auc: 0.90621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if True: #model record\n",
    "    params = {\n",
    "        \"type\": \"Sepsis-original\",\n",
    "        \"model\": 'MLP', #baseline = 'resnet18'\n",
    "        \"model_depth\": 3,\n",
    "        \"device\": \"cuda\",\n",
    "        \"opt\": \"Adam\",\n",
    "        \"lr\": 0.003, #baseline = 0.003\n",
    "        \"batch_size\": 256, #baseline resnet18 : 8\n",
    "        \"epochs\": 150,\n",
    "        \"fixing\": \"None\"\n",
    "        }\n",
    "training_set = TensorDataset(torch.FloatTensor(X_train_), torch.FloatTensor(y_train_))\n",
    "\n",
    "# checkpoint setting\n",
    "project_name = f\"{params['type']} - {params['model']}{params['model_depth']} - lr_{params['lr']} - CEL\"\n",
    "project_folder = f\"2021.12.10.t2 - Sepsis - MLP - {params['type']}\"\n",
    "ck_pth = f'./checkpoint/{project_folder}'\n",
    "if os.path.exists(ck_pth)==False:\n",
    "    os.mkdir(ck_pth)\n",
    "ck_name = project_name\n",
    "path = f'./checkpoint/{project_folder}/{project_name}.txt'\n",
    "f = open(path, 'w')\n",
    "lines = params\n",
    "f.writelines([f'{i} : {params[i]} \\n' for i in params])\n",
    "f.close()\n",
    "tensorboard_logdir = f'./logsdir/S2/ {project_folder} - {project_name}'\n",
    "writer=SummaryWriter(tensorboard_logdir)\n",
    "model = model_create()\n",
    "loss = torch.nn.BCELoss()\n",
    "if params['opt']=='Adam':\n",
    "    optimizer = Adam(model.parameters(), lr=params['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'], weight_decay = 1e-4, momentum=0.9)\n",
    "logs  = train_valid_process_main(model, training_set, params['batch_size'])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "///-------original model-------///\n",
      "Accuracy: 0.92806 \n",
      "AUC: 0.89147\n"
     ]
    }
   ],
   "source": [
    "validation_set = TensorDataset(torch.FloatTensor(X_test_), torch.FloatTensor(y_test_))\n",
    "test_loader = DataLoader(validation_set, batch_size=139, shuffle=False)\n",
    "checkpoint_path = f'./checkpoint/{project_folder}/best - tauc - Sepsis-original - MLP3 - lr_0.003 - CEL.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "model = model_create()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to('cpu')\n",
    "with torch.no_grad():\n",
    "    for i, (text, label) in enumerate(test_loader, start=1):\n",
    "        output = model(text.to('cpu'))\n",
    "        label = label\n",
    "    acc = metrics.accuracy_score(output>0.5, label)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, output, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print(\"///-------original model-------///\")\n",
    "    print(\"Accuracy:\", round(acc,5), \"\\nAUC:\", round(auc,5))\n",
    "\n",
    "# Dataset Scale\n",
    "# train  [0:  385, 1: 31]\n",
    "# valid  [0: 129, 1: 10] (test)\n",
    "\n",
    "# Test 結果\n",
    "# 沒有初始化model weight\n",
    "# Accuracy: 0.94964 \n",
    "# AUC: 0.94109\n",
    "\n",
    "# 有初始化model weight\n",
    "# Accuracy: 0.92806 \n",
    "# AUC: 0.89147"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cefeaee0cb99e52f47ecbf6a0fec4d636206690d7e9c62031f057a9471691d65"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('lstm_pyt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from Bio import SeqIO\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "from function import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nas_path = \"./dataset/\"\n",
    "# lineage_label = np.array(pd.read_csv(os.path.join(nas_path, './1404_lineage_report and metadata 20220316.csv'))[['lineage_x','diff']])\n",
    "# label_ = []\n",
    "# new_lineage_label = []\n",
    "# for idx, rna in enumerate(SeqIO.parse(os.path.join(nas_path, './1404.sequences.aln.fasta') ,\"fasta\")):\n",
    "#     if \"B.1.617.2\" == lineage_label[idx][0]:\n",
    "#     # break\n",
    "#     # print(lineage_label[idx][0].split(' ')[0])\n",
    "#         label_.append(lineage_label[idx][1].split(' ')[0])\n",
    "\n",
    "#         new_lineage_label.append(str(rna.seq))\n",
    "# print('sample:', len(new_lineage_label))\n",
    "# class_,_ ,_,_= np.unique(label_,return_counts=True,return_index=True,return_inverse=True)\n",
    "# print(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_search = {}\n",
    "# for idx, i in enumerate('-NACGT'):\n",
    "\n",
    "#     dict_search[i] = idx\n",
    "# print(dict_search)\n",
    "# from tqdm.notebook import tqdm\n",
    "# num_new_sequences =[]\n",
    "# for k in tqdm(new_lineage_label):\n",
    "# \ttemp_store=[]\n",
    "# \tfor j in k:\n",
    "# \t\t# temp_store.append(clean(j)) #one hot\n",
    "# \t\ttemp_store.append(dict_search[clean(j)])\n",
    "# \tnum_new_sequences.append(temp_store)\n",
    "# total_sequence_array = np.array(num_new_sequences)\n",
    "# print(total_sequence_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from function import LogScaler\n",
    "# ln = LogScaler()\n",
    "# X_train_norm = ln.fit_transform(total_sequence_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del new_lineage_label, num_new_sequences\n",
    "# new_lineage_label = total_sequence_array\n",
    "# one_hot_search_dict = {'C': [1,0,0,0,0,0], 'G': [0,1,0,0,0,0], 'A': [0,0,1,0,0,0],  'T': [0,0,0,1,0,0], 'N': [0,0,0,0,1,0],  '-': [0,0,0,0,0,1]}\n",
    "\n",
    "# num_new_sequences =[]\n",
    "# for k in tqdm(new_lineage_label):\n",
    "# \ttemp_single_seq_transfer = []\n",
    "# \tfor j in k:\n",
    "# \t\ttemp_single_seq_transfer+=one_hot_search_dict[j]\n",
    "# \tnum_new_sequences.append(temp_single_seq_transfer)\n",
    "# total_sequence_array = np.array(num_new_sequences)\n",
    "# print(total_sequence_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_dict_ = {}\n",
    "# for idx, i in enumerate(class_):\n",
    "#     class_dict_[i] = idx\n",
    "# print(class_dict_)\n",
    "# multi_label = []\n",
    "# for i in label_:\n",
    "#     multi_label.append(class_dict_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"gene.npy\" ,total_sequence_array)\n",
    "# np.save(\"label.npy\" ,multi_label)\n",
    "total_sequence_array = np.load('./gene.npy')\n",
    "multi_label = np.load(\"./label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "#onehot\n",
    "X_train, X_test, y_train, y_test = train_test_split(total_sequence_array, multi_label,stratify = multi_label, test_size=0.25, random_state=42) \n",
    "# non onehot\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train_norm, multi_label,stratify = multi_label, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "torch.manual_seed(2020)\n",
    "\n",
    "class TransferDataset(Dataset):\n",
    "    def __init__(self, s_path, labels):\n",
    "        self.s_path = s_path\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.s_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        singel_image_ = self.s_path[idx].astype(np.float32)\n",
    "        # print(singel_image_.shape)\n",
    "        seed = np.random.randint(1e9)       \n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        singel_image_ = torch.FloatTensor(singel_image_)\n",
    "        label = int(self.labels[idx])\n",
    "        # print(label)\n",
    "\n",
    "        return singel_image_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851 284\n"
     ]
    }
   ],
   "source": [
    "train_ds = TransferDataset(s_path= X_train, labels= y_train)\n",
    "test_ds = TransferDataset(s_path= X_test, labels= y_test)\n",
    "print(len(train_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_mlp\n",
    "# from model_mlp import MLP\n",
    "from model_mlp_seq import MLP\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(2, X_train.shape[1]).to(device)\n",
    "# model.initialize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import metrics\n",
    "def clip_gradient(optimizer, grad_clip):\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
    "\n",
    "def loss_epoch(model,loss_func,dataset_dl,sanity_check=False,opt=None):\n",
    "    running_loss=0.0\n",
    "    running_metric=0.0\n",
    "\n",
    "    len_data = len(dataset_dl)\n",
    "    for xb, yb in (dataset_dl):\n",
    "    # for xb, yb in (dataset_dl):\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        # print(type(xb), type(yb.shape))\n",
    "        # output=torch.squeeze(torch.sigmoid(model(xb)))\n",
    "        output=torch.squeeze(model(xb))\n",
    "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt)\n",
    "        running_loss+=loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric+=metric_b\n",
    "\n",
    "        if sanity_check is True:\n",
    "            break\n",
    "    loss=running_loss/float(len_data)\n",
    "    metric=running_metric/float(len_data)\n",
    "    return loss, metric\n",
    "\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def metrics_batch(output, target):\n",
    "    # print(target)\n",
    "    # print(torch.argmax(output, dim=1))\n",
    "    acc = metrics.accuracy_score(target.cpu().detach().numpy(), torch.argmax(output, dim=1).cpu().detach().numpy()>0.5)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    with torch.no_grad():\n",
    "        metric_b = metrics_batch(output,target)\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "def train_val(model, params):\n",
    "    num_epochs=params[\"num_epochs\"]\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "    \n",
    "    loss_history={\n",
    "        \"train\": [],\n",
    "        \"val\": [],\n",
    "    }\n",
    "    \n",
    "    metric_history={\n",
    "        \"train\": [],\n",
    "        \"val\": [],\n",
    "    }\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss=float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr=get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr))\n",
    "        model.train()\n",
    "        train_loss, train_metric=loss_epoch(model,loss_func,train_dl,sanity_check,opt)\n",
    "        loss_history[\"train\"].append(train_loss)\n",
    "        metric_history[\"train\"].append(train_metric)\n",
    " \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric=loss_epoch(model,loss_func,val_dl,sanity_check)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print(\"Copied best model weights!\")\n",
    "        \n",
    "        loss_history[\"val\"].append(val_loss)\n",
    "        metric_history[\"val\"].append(val_metric)\n",
    "\n",
    "        \n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            print(\"Loading best model weights!\")\n",
    "            model.load_state_dict(best_model_wts)\n",
    "        \n",
    "\n",
    "        print(\"train loss: %.6f, dev loss: %.6f,  train accuracy: %.2f,valid accuracy: %.2f\" %(train_loss,val_loss, 100*train_metric,100*val_metric))\n",
    "        print(\"-\"*10) \n",
    "    model.load_state_dict(best_model_wts)\n",
    "        \n",
    "    return loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_mlp\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "# loss_func = nn.BCELoss(reduction='mean')\n",
    "opt = optim.Adam(model.parameters(), lr=0.003)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199, current lr=0.003\n",
      "Copied best model weights!\n",
      "train loss: 21.009518, dev loss: 50.468019,  train accuracy: 61.21,valid accuracy: 41.52\n",
      "----------\n",
      "Epoch 1/199, current lr=0.003\n",
      "Copied best model weights!\n",
      "train loss: 18.408672, dev loss: 41.351103,  train accuracy: 72.02,valid accuracy: 47.50\n",
      "----------\n",
      "Epoch 2/199, current lr=0.003\n",
      "train loss: 15.726642, dev loss: 50.597941,  train accuracy: 81.75,valid accuracy: 41.65\n",
      "----------\n",
      "Epoch 3/199, current lr=0.003\n",
      "train loss: 16.202225, dev loss: 49.335926,  train accuracy: 78.31,valid accuracy: 45.04\n",
      "----------\n",
      "Epoch 4/199, current lr=0.003\n",
      "train loss: 13.736496, dev loss: 50.594074,  train accuracy: 88.33,valid accuracy: 43.39\n",
      "----------\n",
      "Epoch 5/199, current lr=0.003\n",
      "train loss: 13.219997, dev loss: 52.041416,  train accuracy: 89.23,valid accuracy: 41.43\n",
      "----------\n",
      "Epoch 6/199, current lr=0.003\n",
      "train loss: 13.628252, dev loss: 48.552215,  train accuracy: 87.50,valid accuracy: 43.93\n",
      "----------\n",
      "Epoch 7/199, current lr=0.003\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Loading best model weights!\n",
      "train loss: 12.719568, dev loss: 49.778360,  train accuracy: 90.70,valid accuracy: 44.64\n",
      "----------\n",
      "Epoch 8/199, current lr=0.0015\n",
      "Copied best model weights!\n",
      "train loss: 15.916246, dev loss: 36.773534,  train accuracy: 81.32,valid accuracy: 61.70\n",
      "----------\n",
      "Epoch 9/199, current lr=0.0015\n",
      "train loss: 14.438980, dev loss: 48.342309,  train accuracy: 85.29,valid accuracy: 45.58\n",
      "----------\n",
      "Epoch 10/199, current lr=0.0015\n",
      "train loss: 14.034611, dev loss: 51.284547,  train accuracy: 87.15,valid accuracy: 43.79\n",
      "----------\n",
      "Epoch 11/199, current lr=0.0015\n",
      "train loss: 13.134640, dev loss: 49.235933,  train accuracy: 90.08,valid accuracy: 43.44\n",
      "----------\n",
      "Epoch 12/199, current lr=0.0015\n",
      "train loss: 12.492980, dev loss: 50.656431,  train accuracy: 91.43,valid accuracy: 42.68\n",
      "----------\n",
      "Epoch 13/199, current lr=0.0015\n",
      "Copied best model weights!\n",
      "train loss: 12.290737, dev loss: 34.901476,  train accuracy: 92.74,valid accuracy: 63.84\n",
      "----------\n",
      "Epoch 14/199, current lr=0.0015\n",
      "train loss: 12.036146, dev loss: 35.069357,  train accuracy: 93.44,valid accuracy: 62.41\n",
      "----------\n",
      "Epoch 15/199, current lr=0.0015\n",
      "train loss: 11.625331, dev loss: 38.091379,  train accuracy: 95.13,valid accuracy: 61.38\n",
      "----------\n",
      "Epoch 16/199, current lr=0.0015\n",
      "train loss: 11.483646, dev loss: 51.560962,  train accuracy: 95.29,valid accuracy: 42.77\n",
      "----------\n",
      "Epoch 17/199, current lr=0.0015\n",
      "Copied best model weights!\n",
      "train loss: 11.383334, dev loss: 31.220983,  train accuracy: 95.75,valid accuracy: 75.18\n",
      "----------\n",
      "Epoch 18/199, current lr=0.0015\n",
      "train loss: 11.218711, dev loss: 38.106702,  train accuracy: 95.95,valid accuracy: 60.98\n",
      "----------\n",
      "Epoch 19/199, current lr=0.0015\n",
      "train loss: 11.320910, dev loss: 38.625225,  train accuracy: 95.29,valid accuracy: 59.42\n",
      "----------\n",
      "Epoch 20/199, current lr=0.0015\n",
      "Copied best model weights!\n",
      "train loss: 11.011926, dev loss: 28.394815,  train accuracy: 96.37,valid accuracy: 80.22\n",
      "----------\n",
      "Epoch 21/199, current lr=0.0015\n",
      "train loss: 10.585832, dev loss: 47.898306,  train accuracy: 98.03,valid accuracy: 46.74\n",
      "----------\n",
      "Epoch 22/199, current lr=0.0015\n",
      "train loss: 11.030660, dev loss: 50.000496,  train accuracy: 96.88,valid accuracy: 44.24\n",
      "----------\n",
      "Epoch 23/199, current lr=0.0015\n",
      "train loss: 10.835882, dev loss: 48.799025,  train accuracy: 97.18,valid accuracy: 45.18\n",
      "----------\n",
      "Epoch 24/199, current lr=0.0015\n",
      "train loss: 10.775663, dev loss: 50.472377,  train accuracy: 97.61,valid accuracy: 42.99\n",
      "----------\n",
      "Epoch 25/199, current lr=0.0015\n",
      "train loss: 10.696854, dev loss: 31.184710,  train accuracy: 97.33,valid accuracy: 73.79\n",
      "----------\n",
      "Epoch 26/199, current lr=0.0015\n",
      "Epoch 00027: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Loading best model weights!\n",
      "train loss: 10.685810, dev loss: 50.176616,  train accuracy: 97.45,valid accuracy: 43.93\n",
      "----------\n",
      "Epoch 27/199, current lr=0.00075\n",
      "Copied best model weights!\n",
      "train loss: 10.659947, dev loss: 27.807402,  train accuracy: 97.80,valid accuracy: 80.22\n",
      "----------\n",
      "Epoch 28/199, current lr=0.00075\n",
      "train loss: 10.543014, dev loss: 30.735875,  train accuracy: 98.26,valid accuracy: 72.90\n",
      "----------\n",
      "Epoch 29/199, current lr=0.00075\n",
      "train loss: 10.404718, dev loss: 49.506216,  train accuracy: 98.84,valid accuracy: 43.84\n",
      "----------\n",
      "Epoch 30/199, current lr=0.00075\n",
      "train loss: 10.321880, dev loss: 38.812732,  train accuracy: 98.84,valid accuracy: 60.45\n",
      "----------\n",
      "Epoch 31/199, current lr=0.00075\n",
      "train loss: 10.380156, dev loss: 49.683553,  train accuracy: 98.84,valid accuracy: 45.49\n",
      "----------\n",
      "Epoch 32/199, current lr=0.00075\n",
      "train loss: 10.303111, dev loss: 32.210574,  train accuracy: 98.84,valid accuracy: 71.70\n",
      "----------\n",
      "Epoch 33/199, current lr=0.00075\n",
      "Epoch 00034: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Loading best model weights!\n",
      "train loss: 10.594737, dev loss: 30.818181,  train accuracy: 97.92,valid accuracy: 74.42\n",
      "----------\n",
      "Epoch 34/199, current lr=0.000375\n",
      "train loss: 10.453176, dev loss: 37.560179,  train accuracy: 98.30,valid accuracy: 60.80\n",
      "----------\n",
      "Epoch 35/199, current lr=0.000375\n",
      "train loss: 10.531135, dev loss: 38.827253,  train accuracy: 98.03,valid accuracy: 57.37\n",
      "----------\n",
      "Epoch 36/199, current lr=0.000375\n",
      "train loss: 10.328425, dev loss: 35.587122,  train accuracy: 98.96,valid accuracy: 63.97\n",
      "----------\n",
      "Epoch 37/199, current lr=0.000375\n",
      "train loss: 10.256901, dev loss: 29.417524,  train accuracy: 99.07,valid accuracy: 76.07\n",
      "----------\n",
      "Epoch 38/199, current lr=0.000375\n",
      "train loss: 10.195619, dev loss: 31.739526,  train accuracy: 99.19,valid accuracy: 72.23\n",
      "----------\n",
      "Epoch 39/199, current lr=0.000375\n",
      "Epoch 00040: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Loading best model weights!\n",
      "train loss: 10.280939, dev loss: 28.331212,  train accuracy: 98.61,valid accuracy: 79.51\n",
      "----------\n",
      "Epoch 40/199, current lr=0.0001875\n",
      "train loss: 10.541141, dev loss: 28.009959,  train accuracy: 98.38,valid accuracy: 80.04\n",
      "----------\n",
      "Epoch 41/199, current lr=0.0001875\n",
      "train loss: 10.382999, dev loss: 27.921310,  train accuracy: 98.73,valid accuracy: 80.04\n",
      "----------\n",
      "Epoch 42/199, current lr=0.0001875\n",
      "train loss: 10.552316, dev loss: 30.478902,  train accuracy: 98.50,valid accuracy: 74.24\n",
      "----------\n",
      "Epoch 43/199, current lr=0.0001875\n",
      "train loss: 10.248723, dev loss: 28.216644,  train accuracy: 99.07,valid accuracy: 79.20\n",
      "----------\n",
      "Epoch 44/199, current lr=0.0001875\n",
      "Copied best model weights!\n",
      "train loss: 10.307442, dev loss: 27.604824,  train accuracy: 98.96,valid accuracy: 79.73\n",
      "----------\n",
      "Epoch 45/199, current lr=0.0001875\n",
      "train loss: 10.282742, dev loss: 28.281340,  train accuracy: 99.07,valid accuracy: 79.11\n",
      "----------\n",
      "Epoch 46/199, current lr=0.0001875\n",
      "train loss: 10.188867, dev loss: 27.616537,  train accuracy: 99.42,valid accuracy: 79.73\n",
      "----------\n",
      "Epoch 47/199, current lr=0.0001875\n",
      "train loss: 10.242297, dev loss: 27.859241,  train accuracy: 99.23,valid accuracy: 79.51\n",
      "----------\n",
      "Epoch 48/199, current lr=0.0001875\n",
      "train loss: 10.194879, dev loss: 27.994973,  train accuracy: 99.54,valid accuracy: 80.13\n",
      "----------\n",
      "Epoch 49/199, current lr=0.0001875\n",
      "train loss: 10.348991, dev loss: 30.970944,  train accuracy: 98.50,valid accuracy: 74.73\n",
      "----------\n",
      "Epoch 50/199, current lr=0.0001875\n",
      "Epoch 00051: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Loading best model weights!\n",
      "train loss: 10.131268, dev loss: 29.924554,  train accuracy: 99.54,valid accuracy: 75.36\n",
      "----------\n",
      "Epoch 51/199, current lr=9.375e-05\n",
      "train loss: 10.271432, dev loss: 28.618472,  train accuracy: 99.07,valid accuracy: 77.46\n",
      "----------\n",
      "Epoch 52/199, current lr=9.375e-05\n",
      "train loss: 10.332014, dev loss: 28.973027,  train accuracy: 98.84,valid accuracy: 77.54\n",
      "----------\n",
      "Epoch 53/199, current lr=9.375e-05\n",
      "train loss: 10.409493, dev loss: 32.445390,  train accuracy: 98.73,valid accuracy: 72.95\n",
      "----------\n",
      "Epoch 54/199, current lr=9.375e-05\n",
      "train loss: 10.169335, dev loss: 28.071867,  train accuracy: 99.23,valid accuracy: 78.88\n",
      "----------\n",
      "Epoch 55/199, current lr=9.375e-05\n",
      "Copied best model weights!\n",
      "train loss: 10.513218, dev loss: 27.586265,  train accuracy: 97.79,valid accuracy: 81.25\n",
      "----------\n",
      "Epoch 56/199, current lr=9.375e-05\n",
      "Copied best model weights!\n",
      "train loss: 10.125213, dev loss: 27.451536,  train accuracy: 99.31,valid accuracy: 79.73\n",
      "----------\n",
      "Epoch 57/199, current lr=9.375e-05\n",
      "train loss: 10.126364, dev loss: 27.645827,  train accuracy: 99.54,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 58/199, current lr=9.375e-05\n",
      "train loss: 10.365288, dev loss: 28.619345,  train accuracy: 98.73,valid accuracy: 78.26\n",
      "----------\n",
      "Epoch 59/199, current lr=9.375e-05\n",
      "train loss: 10.423127, dev loss: 27.500163,  train accuracy: 98.15,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 60/199, current lr=9.375e-05\n",
      "train loss: 10.126611, dev loss: 27.700040,  train accuracy: 99.42,valid accuracy: 80.54\n",
      "----------\n",
      "Epoch 61/199, current lr=9.375e-05\n",
      "train loss: 10.080619, dev loss: 28.266483,  train accuracy: 99.65,valid accuracy: 79.20\n",
      "----------\n",
      "Epoch 62/199, current lr=9.375e-05\n",
      "Copied best model weights!\n",
      "train loss: 10.214769, dev loss: 27.401077,  train accuracy: 99.07,valid accuracy: 81.56\n",
      "----------\n",
      "Epoch 63/199, current lr=9.375e-05\n",
      "train loss: 10.260888, dev loss: 27.578104,  train accuracy: 98.84,valid accuracy: 79.82\n",
      "----------\n",
      "Epoch 64/199, current lr=9.375e-05\n",
      "train loss: 10.053380, dev loss: 28.756139,  train accuracy: 99.65,valid accuracy: 78.26\n",
      "----------\n",
      "Epoch 65/199, current lr=9.375e-05\n",
      "train loss: 10.169275, dev loss: 29.044424,  train accuracy: 99.34,valid accuracy: 76.21\n",
      "----------\n",
      "Epoch 66/199, current lr=9.375e-05\n",
      "train loss: 10.158909, dev loss: 27.437430,  train accuracy: 99.31,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 67/199, current lr=9.375e-05\n",
      "train loss: 10.105246, dev loss: 27.919667,  train accuracy: 99.54,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 68/199, current lr=9.375e-05\n",
      "Epoch 00069: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Loading best model weights!\n",
      "train loss: 10.118041, dev loss: 27.752137,  train accuracy: 99.42,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 69/199, current lr=4.6875e-05\n",
      "train loss: 10.091793, dev loss: 27.566998,  train accuracy: 99.42,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 70/199, current lr=4.6875e-05\n",
      "train loss: 10.203802, dev loss: 28.154905,  train accuracy: 99.31,valid accuracy: 79.29\n",
      "----------\n",
      "Epoch 71/199, current lr=4.6875e-05\n",
      "train loss: 10.188303, dev loss: 27.993209,  train accuracy: 98.99,valid accuracy: 78.88\n",
      "----------\n",
      "Epoch 72/199, current lr=4.6875e-05\n",
      "train loss: 10.209902, dev loss: 30.319329,  train accuracy: 99.19,valid accuracy: 75.36\n",
      "----------\n",
      "Epoch 73/199, current lr=4.6875e-05\n",
      "Copied best model weights!\n",
      "train loss: 10.121857, dev loss: 27.195888,  train accuracy: 99.54,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 74/199, current lr=4.6875e-05\n",
      "train loss: 10.141526, dev loss: 27.348824,  train accuracy: 99.31,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 75/199, current lr=4.6875e-05\n",
      "train loss: 10.198101, dev loss: 27.529781,  train accuracy: 99.11,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 76/199, current lr=4.6875e-05\n",
      "train loss: 10.098616, dev loss: 27.428314,  train accuracy: 99.65,valid accuracy: 79.42\n",
      "----------\n",
      "Epoch 77/199, current lr=4.6875e-05\n",
      "train loss: 10.091523, dev loss: 27.491871,  train accuracy: 99.54,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 78/199, current lr=4.6875e-05\n",
      "train loss: 10.159900, dev loss: 27.867987,  train accuracy: 98.92,valid accuracy: 80.22\n",
      "----------\n",
      "Epoch 79/199, current lr=4.6875e-05\n",
      "Epoch 00080: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Loading best model weights!\n",
      "train loss: 10.295769, dev loss: 27.581510,  train accuracy: 98.88,valid accuracy: 80.13\n",
      "----------\n",
      "Epoch 80/199, current lr=2.34375e-05\n",
      "Copied best model weights!\n",
      "train loss: 10.200553, dev loss: 27.139953,  train accuracy: 99.07,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 81/199, current lr=2.34375e-05\n",
      "train loss: 10.008938, dev loss: 27.366842,  train accuracy: 99.65,valid accuracy: 82.19\n",
      "----------\n",
      "Epoch 82/199, current lr=2.34375e-05\n",
      "train loss: 10.241726, dev loss: 27.349134,  train accuracy: 98.96,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 83/199, current lr=2.34375e-05\n",
      "train loss: 10.113754, dev loss: 27.637711,  train accuracy: 99.65,valid accuracy: 80.22\n",
      "----------\n",
      "Epoch 84/199, current lr=2.34375e-05\n",
      "train loss: 10.192000, dev loss: 27.390250,  train accuracy: 99.19,valid accuracy: 79.42\n",
      "----------\n",
      "Epoch 85/199, current lr=2.34375e-05\n",
      "train loss: 10.182386, dev loss: 27.351135,  train accuracy: 99.31,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 86/199, current lr=2.34375e-05\n",
      "Epoch 00087: reducing learning rate of group 0 to 1.1719e-05.\n",
      "Loading best model weights!\n",
      "train loss: 10.244002, dev loss: 27.350093,  train accuracy: 99.07,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 87/199, current lr=1.171875e-05\n",
      "train loss: 10.132514, dev loss: 27.378306,  train accuracy: 99.42,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 88/199, current lr=1.171875e-05\n",
      "train loss: 10.115566, dev loss: 27.211589,  train accuracy: 99.19,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 89/199, current lr=1.171875e-05\n",
      "train loss: 10.157499, dev loss: 27.349856,  train accuracy: 99.19,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 90/199, current lr=1.171875e-05\n",
      "train loss: 10.175695, dev loss: 27.300978,  train accuracy: 99.31,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 91/199, current lr=1.171875e-05\n",
      "train loss: 10.114085, dev loss: 27.312319,  train accuracy: 99.42,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 92/199, current lr=1.171875e-05\n",
      "Epoch 00093: reducing learning rate of group 0 to 5.8594e-06.\n",
      "Loading best model weights!\n",
      "train loss: 10.119824, dev loss: 27.280483,  train accuracy: 99.31,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 93/199, current lr=5.859375e-06\n",
      "train loss: 10.126160, dev loss: 27.256142,  train accuracy: 99.42,valid accuracy: 81.79\n",
      "----------\n",
      "Epoch 94/199, current lr=5.859375e-06\n",
      "train loss: 10.030978, dev loss: 27.426094,  train accuracy: 99.65,valid accuracy: 81.56\n",
      "----------\n",
      "Epoch 95/199, current lr=5.859375e-06\n",
      "train loss: 10.174944, dev loss: 27.369902,  train accuracy: 99.31,valid accuracy: 81.25\n",
      "----------\n",
      "Epoch 96/199, current lr=5.859375e-06\n",
      "train loss: 10.233119, dev loss: 27.187191,  train accuracy: 99.07,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 97/199, current lr=5.859375e-06\n",
      "train loss: 10.258301, dev loss: 27.516438,  train accuracy: 99.07,valid accuracy: 81.88\n",
      "----------\n",
      "Epoch 98/199, current lr=5.859375e-06\n",
      "Epoch 00099: reducing learning rate of group 0 to 2.9297e-06.\n",
      "Loading best model weights!\n",
      "train loss: 10.106463, dev loss: 27.156625,  train accuracy: 99.42,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 99/199, current lr=2.9296875e-06\n",
      "Copied best model weights!\n",
      "train loss: 10.175960, dev loss: 27.122469,  train accuracy: 99.19,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 100/199, current lr=2.9296875e-06\n",
      "train loss: 10.213939, dev loss: 27.190762,  train accuracy: 99.07,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 101/199, current lr=2.9296875e-06\n",
      "train loss: 10.234026, dev loss: 27.281288,  train accuracy: 98.96,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 102/199, current lr=2.9296875e-06\n",
      "train loss: 10.204924, dev loss: 27.204237,  train accuracy: 99.19,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 103/199, current lr=2.9296875e-06\n",
      "train loss: 10.250256, dev loss: 27.128722,  train accuracy: 98.96,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 104/199, current lr=2.9296875e-06\n",
      "train loss: 10.166401, dev loss: 27.171944,  train accuracy: 99.19,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 105/199, current lr=2.9296875e-06\n",
      "Epoch 00106: reducing learning rate of group 0 to 1.4648e-06.\n",
      "Loading best model weights!\n",
      "train loss: 10.131067, dev loss: 27.379233,  train accuracy: 99.42,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 106/199, current lr=1.46484375e-06\n",
      "Copied best model weights!\n",
      "train loss: 10.250849, dev loss: 27.121405,  train accuracy: 98.96,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 107/199, current lr=1.46484375e-06\n",
      "train loss: 10.259671, dev loss: 27.422292,  train accuracy: 98.96,valid accuracy: 79.42\n",
      "----------\n",
      "Epoch 108/199, current lr=1.46484375e-06\n",
      "train loss: 10.239369, dev loss: 27.196247,  train accuracy: 98.96,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 109/199, current lr=1.46484375e-06\n",
      "Copied best model weights!\n",
      "train loss: 10.214994, dev loss: 27.039871,  train accuracy: 99.07,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 110/199, current lr=1.46484375e-06\n",
      "train loss: 10.132993, dev loss: 27.511416,  train accuracy: 99.23,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 111/199, current lr=1.46484375e-06\n",
      "train loss: 10.077133, dev loss: 27.328005,  train accuracy: 99.65,valid accuracy: 82.19\n",
      "----------\n",
      "Epoch 112/199, current lr=1.46484375e-06\n",
      "train loss: 10.175485, dev loss: 27.582770,  train accuracy: 99.34,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 113/199, current lr=1.46484375e-06\n",
      "train loss: 10.235502, dev loss: 27.477539,  train accuracy: 99.31,valid accuracy: 80.13\n",
      "----------\n",
      "Epoch 114/199, current lr=1.46484375e-06\n",
      "train loss: 10.121376, dev loss: 27.084030,  train accuracy: 99.31,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 115/199, current lr=1.46484375e-06\n",
      "Epoch 00116: reducing learning rate of group 0 to 7.3242e-07.\n",
      "Loading best model weights!\n",
      "train loss: 10.086631, dev loss: 27.146581,  train accuracy: 99.31,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 116/199, current lr=7.32421875e-07\n",
      "train loss: 10.155398, dev loss: 27.318089,  train accuracy: 99.31,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 117/199, current lr=7.32421875e-07\n",
      "train loss: 10.200119, dev loss: 27.468377,  train accuracy: 99.19,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 118/199, current lr=7.32421875e-07\n",
      "train loss: 10.187154, dev loss: 27.443951,  train accuracy: 99.19,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 119/199, current lr=7.32421875e-07\n",
      "train loss: 10.344504, dev loss: 27.536040,  train accuracy: 98.41,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 120/199, current lr=7.32421875e-07\n",
      "train loss: 10.057849, dev loss: 27.156538,  train accuracy: 99.65,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 121/199, current lr=7.32421875e-07\n",
      "Epoch 00122: reducing learning rate of group 0 to 3.6621e-07.\n",
      "Loading best model weights!\n",
      "train loss: 10.161799, dev loss: 27.267422,  train accuracy: 99.31,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 122/199, current lr=3.662109375e-07\n",
      "train loss: 10.166844, dev loss: 27.328402,  train accuracy: 99.19,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 123/199, current lr=3.662109375e-07\n",
      "train loss: 10.105535, dev loss: 27.338433,  train accuracy: 99.54,valid accuracy: 80.54\n",
      "----------\n",
      "Epoch 124/199, current lr=3.662109375e-07\n",
      "train loss: 10.167962, dev loss: 27.561133,  train accuracy: 99.23,valid accuracy: 81.47\n",
      "----------\n",
      "Epoch 125/199, current lr=3.662109375e-07\n",
      "train loss: 10.032652, dev loss: 27.240175,  train accuracy: 99.65,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 126/199, current lr=3.662109375e-07\n",
      "train loss: 10.087493, dev loss: 27.360909,  train accuracy: 99.65,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 127/199, current lr=3.662109375e-07\n",
      "Epoch 00128: reducing learning rate of group 0 to 1.8311e-07.\n",
      "Loading best model weights!\n",
      "train loss: 10.161927, dev loss: 27.385171,  train accuracy: 98.88,valid accuracy: 79.82\n",
      "----------\n",
      "Epoch 128/199, current lr=1.8310546875e-07\n",
      "train loss: 10.097550, dev loss: 27.128063,  train accuracy: 99.54,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 129/199, current lr=1.8310546875e-07\n",
      "train loss: 10.343117, dev loss: 27.174712,  train accuracy: 98.84,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 130/199, current lr=1.8310546875e-07\n",
      "train loss: 10.197087, dev loss: 27.265186,  train accuracy: 99.07,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 131/199, current lr=1.8310546875e-07\n",
      "train loss: 10.425428, dev loss: 27.178203,  train accuracy: 98.18,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 132/199, current lr=1.8310546875e-07\n",
      "train loss: 10.111614, dev loss: 27.329937,  train accuracy: 99.42,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 133/199, current lr=1.8310546875e-07\n",
      "Epoch 00134: reducing learning rate of group 0 to 9.1553e-08.\n",
      "Loading best model weights!\n",
      "train loss: 10.042213, dev loss: 27.333172,  train accuracy: 99.88,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 134/199, current lr=9.1552734375e-08\n",
      "train loss: 10.298195, dev loss: 27.377652,  train accuracy: 98.96,valid accuracy: 79.82\n",
      "----------\n",
      "Epoch 135/199, current lr=9.1552734375e-08\n",
      "train loss: 10.260245, dev loss: 27.245644,  train accuracy: 99.07,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 136/199, current lr=9.1552734375e-08\n",
      "train loss: 10.258336, dev loss: 27.344038,  train accuracy: 99.07,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 137/199, current lr=9.1552734375e-08\n",
      "train loss: 10.184535, dev loss: 27.308716,  train accuracy: 99.31,valid accuracy: 79.73\n",
      "----------\n",
      "Epoch 138/199, current lr=9.1552734375e-08\n",
      "train loss: 10.234271, dev loss: 27.052207,  train accuracy: 98.96,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 139/199, current lr=9.1552734375e-08\n",
      "Epoch 00140: reducing learning rate of group 0 to 4.5776e-08.\n",
      "Loading best model weights!\n",
      "train loss: 10.232353, dev loss: 27.053403,  train accuracy: 99.19,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 140/199, current lr=4.57763671875e-08\n",
      "train loss: 10.071643, dev loss: 27.318142,  train accuracy: 99.46,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 141/199, current lr=4.57763671875e-08\n",
      "train loss: 10.290581, dev loss: 27.401817,  train accuracy: 98.84,valid accuracy: 81.56\n",
      "----------\n",
      "Epoch 142/199, current lr=4.57763671875e-08\n",
      "train loss: 10.315162, dev loss: 27.169723,  train accuracy: 98.73,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 143/199, current lr=4.57763671875e-08\n",
      "train loss: 10.192362, dev loss: 27.293060,  train accuracy: 99.07,valid accuracy: 80.13\n",
      "----------\n",
      "Epoch 144/199, current lr=4.57763671875e-08\n",
      "train loss: 10.175630, dev loss: 27.162568,  train accuracy: 99.31,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 145/199, current lr=4.57763671875e-08\n",
      "Epoch 00146: reducing learning rate of group 0 to 2.2888e-08.\n",
      "Loading best model weights!\n",
      "train loss: 10.172593, dev loss: 27.234114,  train accuracy: 99.31,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 146/199, current lr=2.288818359375e-08\n",
      "train loss: 10.056123, dev loss: 27.117892,  train accuracy: 99.77,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 147/199, current lr=2.288818359375e-08\n",
      "train loss: 10.294757, dev loss: 27.247767,  train accuracy: 98.53,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 148/199, current lr=2.288818359375e-08\n",
      "train loss: 10.164508, dev loss: 27.232796,  train accuracy: 99.31,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 149/199, current lr=2.288818359375e-08\n",
      "train loss: 10.254214, dev loss: 27.148873,  train accuracy: 98.92,valid accuracy: 82.10\n",
      "----------\n",
      "Epoch 150/199, current lr=2.288818359375e-08\n",
      "train loss: 10.156846, dev loss: 27.209177,  train accuracy: 99.42,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 151/199, current lr=2.288818359375e-08\n",
      "Epoch 00152: reducing learning rate of group 0 to 1.1444e-08.\n",
      "Loading best model weights!\n",
      "train loss: 10.244746, dev loss: 27.281151,  train accuracy: 98.84,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 152/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.179733, dev loss: 27.562198,  train accuracy: 99.07,valid accuracy: 80.13\n",
      "----------\n",
      "Epoch 153/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.243564, dev loss: 27.426791,  train accuracy: 98.84,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 154/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.109738, dev loss: 27.168889,  train accuracy: 99.34,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 155/199, current lr=1.1444091796875e-08\n",
      "Copied best model weights!\n",
      "train loss: 10.203072, dev loss: 27.026152,  train accuracy: 98.99,valid accuracy: 81.70\n",
      "----------\n",
      "Epoch 156/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.204226, dev loss: 27.545445,  train accuracy: 98.84,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 157/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.110016, dev loss: 27.222772,  train accuracy: 99.54,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 158/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.136291, dev loss: 27.476526,  train accuracy: 99.31,valid accuracy: 79.42\n",
      "----------\n",
      "Epoch 159/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.135752, dev loss: 27.131340,  train accuracy: 99.19,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 160/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.195792, dev loss: 27.538293,  train accuracy: 99.23,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 161/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.159165, dev loss: 27.289037,  train accuracy: 99.31,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 162/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.139207, dev loss: 27.255102,  train accuracy: 99.31,valid accuracy: 80.13\n",
      "----------\n",
      "Epoch 163/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.262704, dev loss: 27.293881,  train accuracy: 98.96,valid accuracy: 82.10\n",
      "----------\n",
      "Epoch 164/199, current lr=1.1444091796875e-08\n",
      "Copied best model weights!\n",
      "train loss: 10.229148, dev loss: 27.007040,  train accuracy: 99.03,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 165/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.213281, dev loss: 27.042527,  train accuracy: 99.31,valid accuracy: 81.70\n",
      "----------\n",
      "Epoch 166/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.164000, dev loss: 27.175975,  train accuracy: 99.54,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 167/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.093800, dev loss: 27.419648,  train accuracy: 99.42,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 168/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.235535, dev loss: 27.197886,  train accuracy: 99.42,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 169/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.099060, dev loss: 27.305633,  train accuracy: 99.65,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 170/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.345797, dev loss: 27.116375,  train accuracy: 98.30,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 171/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.270041, dev loss: 27.407117,  train accuracy: 98.96,valid accuracy: 80.04\n",
      "----------\n",
      "Epoch 172/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.207779, dev loss: 27.678782,  train accuracy: 99.19,valid accuracy: 79.51\n",
      "----------\n",
      "Epoch 173/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.142125, dev loss: 27.465559,  train accuracy: 99.31,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 174/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.222916, dev loss: 27.193100,  train accuracy: 99.19,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 175/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.130995, dev loss: 27.201832,  train accuracy: 99.42,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 176/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.123330, dev loss: 27.183186,  train accuracy: 99.19,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 177/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.109194, dev loss: 27.301604,  train accuracy: 99.54,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 178/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.320199, dev loss: 27.404999,  train accuracy: 98.50,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 179/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.276907, dev loss: 27.340069,  train accuracy: 99.07,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 180/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.366339, dev loss: 27.172713,  train accuracy: 98.61,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 181/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.286830, dev loss: 27.523456,  train accuracy: 98.96,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 182/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.233201, dev loss: 27.452257,  train accuracy: 98.88,valid accuracy: 81.16\n",
      "----------\n",
      "Epoch 183/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.243011, dev loss: 27.202644,  train accuracy: 99.07,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 184/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.033064, dev loss: 27.275484,  train accuracy: 99.65,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 185/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.294153, dev loss: 27.133360,  train accuracy: 98.96,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 186/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.036781, dev loss: 27.129751,  train accuracy: 99.54,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 187/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.202744, dev loss: 27.392998,  train accuracy: 99.07,valid accuracy: 80.13\n",
      "----------\n",
      "Epoch 188/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.126114, dev loss: 27.320319,  train accuracy: 99.54,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 189/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.200574, dev loss: 27.095179,  train accuracy: 99.19,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 190/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.141513, dev loss: 27.364049,  train accuracy: 99.42,valid accuracy: 81.47\n",
      "----------\n",
      "Epoch 191/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.176843, dev loss: 27.376324,  train accuracy: 99.19,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 192/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.090249, dev loss: 27.125267,  train accuracy: 99.46,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 193/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.095083, dev loss: 27.161245,  train accuracy: 99.54,valid accuracy: 81.07\n",
      "----------\n",
      "Epoch 194/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.125287, dev loss: 27.328976,  train accuracy: 99.65,valid accuracy: 80.04\n",
      "----------\n",
      "Epoch 195/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.163993, dev loss: 27.646906,  train accuracy: 99.42,valid accuracy: 80.85\n",
      "----------\n",
      "Epoch 196/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.105632, dev loss: 27.402363,  train accuracy: 99.54,valid accuracy: 80.45\n",
      "----------\n",
      "Epoch 197/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.129666, dev loss: 27.242588,  train accuracy: 99.42,valid accuracy: 80.76\n",
      "----------\n",
      "Epoch 198/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.187539, dev loss: 27.170468,  train accuracy: 99.19,valid accuracy: 81.38\n",
      "----------\n",
      "Epoch 199/199, current lr=1.1444091796875e-08\n",
      "train loss: 10.181893, dev loss: 27.440508,  train accuracy: 99.07,valid accuracy: 81.16\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dl = DataLoader(train_ds, batch_size= batch_size, \n",
    "                        shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size= 2*batch_size, \n",
    "                        shuffle=False)  \n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "# path2weights = \"./models/weights_MLP_binaryclass(onehot).2022.05.24.pt\"\n",
    "path2weights = \"./models/weights_MLP_binaryclass(onehot)-[model sequential class'0.1'] .2022.05.26.pth\"\n",
    "params_train={\n",
    "    \"num_epochs\": 200,\n",
    "    \"optimizer\": opt,\n",
    "    \"loss_func\": loss_func,\n",
    "    \"train_dl\": train_dl,\n",
    "    \"val_dl\": test_dl,\n",
    "    \"sanity_check\": False,\n",
    "    \"lr_scheduler\": lr_scheduler,\n",
    "    \"path2weights\": path2weights,\n",
    "    }\n",
    "\n",
    "loss_history, metric_history  = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'loss history')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history['train'])\n",
    "plt.plot(loss_history['val'])\n",
    "plt.legend(['train','val'])\n",
    "plt.title('loss history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'onehot accuracy history')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(metric_history['train'])\n",
    "plt.plot(metric_history['val'])\n",
    "plt.legend(['train','val'])\n",
    "plt.title('onehot accuracy history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bf9715d586f3699c5b6f8492f6b27cb69cc908a6342b6e29112248c55ec895c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ptenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

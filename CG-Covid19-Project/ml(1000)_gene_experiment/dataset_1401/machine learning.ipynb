{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/john/network/cnn/deepinsight/dataset_1401'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "# from isoweek import Week\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data pro-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_file = './1404.sequences.aln.fasta'\n",
    "metadata_file = './1404_lineage_report and metadata 20220316.csv'\n",
    "referenceFile = './onehot-reference.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1053, 13) (351, 13)\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(metadata_file,encoding='ISO-8859-1')\n",
    "\n",
    "# split data\n",
    "nonChange = metadata.loc[metadata['diff']=='N']\n",
    "trainN,testN=train_test_split(nonChange,test_size= 0.25, random_state=42)\n",
    "\n",
    "Change = metadata.loc[metadata['diff']=='Y']\n",
    "trainY,testY=train_test_split(Change,test_size= 0.25, random_state=42)\n",
    "\n",
    "traindata = trainN.append(trainY)\n",
    "testdata = testN.append(testY)\n",
    "\n",
    "print(traindata.shape, testdata.shape)\n",
    "traindata.to_csv('y_train.csv',index=False)\n",
    "testdata.to_csv('y_test.csv',index=False)\n",
    "# np.save('y_train',traindata['diff'])\n",
    "# np.save('y_test',testdata['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './onehot-reference.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25917/4230736863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcurrentSeq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mreferenceSeq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindReferenceSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25917/4230736863.py\u001b[0m in \u001b[0;36mfindReferenceSeq\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfindReferenceSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                 \u001b[0mcurrentSeq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './onehot-reference.fasta'"
     ]
    }
   ],
   "source": [
    "def findReferenceSeq():\n",
    "\twith open(referenceFile) as f:\n",
    "\t\tcurrentSeq = \"\"\n",
    "\n",
    "\t\tfor line in f:\n",
    "\t\t\tif \">\" not in line:\n",
    "\t\t\t\tcurrentSeq = currentSeq + line.strip()\n",
    "\n",
    "\tf.close()\n",
    "\treturn currentSeq\n",
    "\n",
    "referenceSeq = findReferenceSeq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for handling weird sequence characters\n",
    "def clean(x, loc):\n",
    "\tx = x.upper() \n",
    "\t\n",
    "\tif x == 'T' or x == 'A' or x == 'G' or x == 'C' or x == '-' or x == 'N':\n",
    "\t\treturn x\n",
    "\n",
    "\tif x == 'U' or x == 'Y':\n",
    "\t\treturn 'T'\n",
    "\t\n",
    "\tif x == 'K' or x == 'S':\n",
    "\t\treturn 'G'\n",
    "\n",
    "\tif x == 'M' or x == 'R' or x == 'W' or x == 'H' or x=='V' or x=='D':\n",
    "\t\treturn 'A'\n",
    "\n",
    "\tif x== 'B':\n",
    "\t\treturn 'C'\n",
    "\t\n",
    "\t# otherwise return value from reference\n",
    "\treturn referenceSeq[loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLine(seqId, seq):\n",
    "\tdataLine = []\n",
    "\tdataLine.append(seqId)\n",
    "\n",
    "\tnewSeq = \"\"\n",
    "\n",
    "\t# for each character in the sequence\n",
    "\tfor index in range(len(seq)):\n",
    "\t\tnewSeq = newSeq + clean(seq[index], index)\n",
    "\n",
    "\tdataLine.append(seq)\n",
    "\t\n",
    "\treturn dataLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files read in, now processing\n",
      "N= 1404\n"
     ]
    }
   ],
   "source": [
    "# data storage\n",
    "dataList = []\n",
    "# dict for lookup efficiency\n",
    "indiciesToKeep = dict()\n",
    "idToLineage = dict()\n",
    "\n",
    "seq_char_dict = {rec.id : rec.seq.upper() for rec in SeqIO.parse(sequences_file, \"fasta\")}\n",
    "\n",
    "def readInAndFormatData():\n",
    "    \n",
    "\t# create a dictionary of sequence ids to their assigned lineages utf-8\n",
    "\twith open(metadata_file, 'r', newline='', encoding='ISO-8859-1') as f:\n",
    "\n",
    "\t\tfor line in f:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\tsplit = line.split(\",\")\n",
    "\t\t\tidToLineage[split[0]] = split[1]\n",
    "\n",
    "\t# close the file\n",
    "\tf.close()\n",
    "\n",
    "\tprint(\"files read in, now processing\")\n",
    "\n",
    "\tfor key in seq_char_dict.keys():\n",
    "\t\t\tif key in idToLineage:\n",
    "\t\t\t\tdataList.append(getDataLine(key, seq_char_dict[key]))\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"unable to find the lineage classification for: \" + key)\n",
    "\n",
    "\tprint('N=',len(dataList))\n",
    "\treturn dataList\n",
    "\t\n",
    "dataList = readInAndFormatData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29903\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(dataList[0][1])):\n",
    "    indiciesToKeep[index] = True\n",
    "    \n",
    "print(len(indiciesToKeep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns from the data list which don't have any SNPs. \n",
    "# We do this because these columns won't be relevant for a logistic regression \n",
    "# which is trying to use differences between sequences to assign lineages\n",
    "def removeOtherIndices(indiciesToKeep):\n",
    "\n",
    "\t# instantiate the final list\n",
    "\tfinalList = []\n",
    "\n",
    "\tindicies = list(indiciesToKeep.keys())\n",
    "\tindicies.sort()\n",
    "\n",
    "\t# while the dataList isn't empty\n",
    "\twhile len(dataList) > 0:\n",
    "\n",
    "\t\t# pop the first line (remove)\n",
    "\t\tline = dataList.pop(0) #reference data\n",
    "\t\tseqId = line.pop(0) # reference sequence ID\n",
    "\n",
    "\t\tline = line[0] #remove sequence name ID\n",
    "\t\t# initialize the finalLine\n",
    "\t\tfinalLine = []\n",
    "\n",
    "\t\tfor index in indicies:\n",
    "\t\t\tif index == 0:\n",
    "\t\t\t\t# if its the first index, then that's the lineage assignment, so keep it\n",
    "\t\t\t\tfinalLine.append(seqId)\n",
    "\t\t\t\tfinalLine.append(line[0])  #0519              \n",
    "\t\t\telse:\n",
    "\t\t\t\t# otherwise keep everything at the indices in indiciesToKeep\n",
    "\t\t\t\tfinalLine.append(line[index])\n",
    "\n",
    "                    \n",
    "\t\t# save the finalLine to the finalList\n",
    "\t\tfinalList.append(finalLine)\n",
    "\n",
    "\t# return\n",
    "\treturn finalList\n",
    "\n",
    "dataList = removeOtherIndices(indiciesToKeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature\n",
    "headers = list(indiciesToKeep.keys())\n",
    "headers[0] = \"taxon\"\n",
    "headers.append(29903) # total length:29903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxon</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29894</th>\n",
       "      <th>29895</th>\n",
       "      <th>29896</th>\n",
       "      <th>29897</th>\n",
       "      <th>29898</th>\n",
       "      <th>29899</th>\n",
       "      <th>29900</th>\n",
       "      <th>29901</th>\n",
       "      <th>29902</th>\n",
       "      <th>29903</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hCoV-19/Botswana/R21B67_BHP_AAB78049/2021</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hCoV-19/Yunnan/YN-24/2021</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hCoV-19/Yunnan/YN-39/2021</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hCoV-19/Australia/QLD2012/2021</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hCoV-19/Australia/QLD2027/2021</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29904 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       taxon  1  2  3  4  5  6  7  8  9  ...  \\\n",
       "0  hCoV-19/Botswana/R21B67_BHP_AAB78049/2021  N  N  N  N  N  N  N  N  N  ...   \n",
       "1                  hCoV-19/Yunnan/YN-24/2021  N  N  N  N  N  N  N  N  N  ...   \n",
       "2                  hCoV-19/Yunnan/YN-39/2021  N  N  N  N  N  N  N  N  N  ...   \n",
       "3             hCoV-19/Australia/QLD2012/2021  N  N  N  N  N  N  N  N  N  ...   \n",
       "4             hCoV-19/Australia/QLD2027/2021  N  N  N  N  N  N  N  N  N  ...   \n",
       "\n",
       "  29894 29895 29896 29897 29898 29899 29900 29901 29902 29903  \n",
       "0     N     N     N     N     N     N     N     N     N     N  \n",
       "1     N     N     N     N     N     N     N     N     N     N  \n",
       "2     N     N     N     N     N     N     N     N     N     N  \n",
       "3     N     N     N     N     N     N     N     N     N     N  \n",
       "4     N     N     N     N     N     N     N     N     N     N  \n",
       "\n",
       "[5 rows x 29904 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima = pd.DataFrame(dataList, columns=headers)\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29903\n"
     ]
    }
   ],
   "source": [
    "# nucleotide symbols which can appear\n",
    "# categories = ['A', 'C', 'G', 'T', '-']\n",
    "categories = ['A', 'C', 'G', 'T', 'N']\n",
    "\n",
    "# one hot encoding of all headers other than the first which is the lineage\n",
    "dummyHeaders = headers[1:]\n",
    "print(len(dummyHeaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'taxon'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add extra rows to ensure all of the categories are represented, as otherwise \n",
    "# not enough columns will be created when we call get_dummies\n",
    "for i in categories:\n",
    "\tline = [i] * len(dataList[0])\n",
    "\tpima.loc[len(pima)] = line\n",
    "\n",
    "# get one-hot encoding\n",
    "pima = pd.get_dummies(pima, columns=dummyHeaders)\n",
    "\n",
    "# get rid of the fake data we just added\n",
    "pima.drop(pima.tail(len(categories)).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = list(pima)\n",
    "print(len(feature_cols))\n",
    "feature_cols.pop(0) # remove column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fliter X_train and X_test\n",
    "train = pima.merge(traindata, how='inner', on='taxon')\n",
    "test = pima.merge(testdata, how='inner', on='taxon')\n",
    "train.to_csv (r'X_train.csv', index = False)\n",
    "test.to_csv (r'X_test.csv', index = False)\n",
    "\n",
    "X_train = train[feature_cols]\n",
    "X_test = test[feature_cols]\n",
    "X_train.to_csv (r'X_train.csv', index = False)\n",
    "X_test.to_csv (r'X_test.csv', index = False)\n",
    "\n",
    "# np.save('X_train',X_train)\n",
    "# np.save('X_test',X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1053, 178334) (351, 178334)\n",
      "(1053,) (351,)\n",
      "178334\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X_train,X_test = np.load('X_train.npy', allow_pickle=True),np.load('X_test.npy', allow_pickle=True)\n",
    "y_train,y_test = np.load('y_train.npy', allow_pickle=True),np.load('y_test.npy', allow_pickle=True)\n",
    "# X_train,X_test = pd.read_csv('X_train.csv'),pd.read_csv('X_test.csv')\n",
    "# y_train,y_test = pd.read_csv('y_train.csv'),pd.read_csv('y_test.csv')\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(len(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV,validation_curve,KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score,f1_score,roc_auc_score, roc_curve\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default= DecisionTreeClassifier(criterion='gini', \n",
    "    splitter='best', \n",
    "    max_depth=None, \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1, \n",
    "    min_weight_fraction_leaf=0.0, \n",
    "    max_features=None,  \n",
    "    random_state= seed, \n",
    "    max_leaf_nodes=None, \n",
    "    min_impurity_decrease=0.0,  \n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0)\n",
    "\n",
    "\n",
    "#Fit the algorithm on the data\n",
    "model_default.fit(X_train,y_train)\n",
    "\n",
    "#Predict training set:\n",
    "train_pred = model_default.predict(X_train)\n",
    "train_predprob = model_default.predict_proba(X_train)\n",
    "\n",
    "#Prediction on tetsing data\n",
    "test_pred = model_default.predict(X_test)\n",
    "test_predprob = model_default.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_train, train_pred))\n",
    "print(metrics.accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Report\")\n",
    "print(\"Train Accuracy : %.4g\" % model_default.score(X_train, y_train))\n",
    "print(\"Test Accuracy : %.4g\" % model_default.score(X_test, y_test))\n",
    "# print(\"AUC Score (Train): %f\" % roc_auc_score(y_train, train_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\"max_depth\":range(10,20),\"min_samples_split\":range(1,10),\"min_samples_leaf\":range(1,5)}\n",
    "gsearch1 = GridSearchCV(estimator=DecisionTreeClassifier(criterion='gini',  \n",
    "                            splitter='best', \n",
    "                            max_depth=None, \n",
    "                            min_samples_split=2, \n",
    "                            min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            max_features=None,  \n",
    "                            random_state=seed, \n",
    "                            max_leaf_nodes=None, \n",
    "                            min_impurity_decrease=0.0,  \n",
    "                            class_weight=None,\n",
    "                            ccp_alpha=0.0),\n",
    "                   param_grid=param_test1,\n",
    "                   cv=10,\n",
    "                   n_jobs=1,\n",
    "                   return_train_score= True)\n",
    "\n",
    "gsearch1_result = gsearch1.fit(X_train,y_train)\n",
    "print(\"Best: %f using %s\" % (gsearch1_result.best_score_, gsearch1_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolder = KFold(n_splits=10,random_state=seed,shuffle = True) #k-folder\n",
    "for idx,(train_index, val_index) in enumerate(kfolder.split(X_train, y_train)):\n",
    "    \n",
    "    if istime == True:\n",
    "        model_out = os.path.join(os.getcwd(),f\"model save//4067.{j}Model_class{classgroup}_default_time.joblib\")\n",
    "    else:\n",
    "        model_out = os.path.join(os.getcwd(),f\"model save//4067.{j}Model_class{classgroup}_default.joblib\")\n",
    "\n",
    "    X_train_, X_val_ = X_train[train_index], X_train[val_index]\n",
    "    y_train_, y_val_ = y_train[train_index], y_train[val_index] \n",
    "\n",
    "    if idx == 0 :\n",
    "        model_default.fit(X_train_,y_train_)\n",
    "\n",
    "        train_accuracy = model_default.score(X_train_, y_train_)\n",
    "        validate_accuracy = model_default.score(X_val_, y_val_)\n",
    "        y_pred = model_default.predict(X_test)\n",
    "        test_accuracy = model_default.score(X_test, y_test)\n",
    "        joblib.dump(model_default,  model_out, compress=9)\n",
    "        index = idx+1\n",
    "\n",
    "    else:\n",
    "        model_default.fit(X_train_,y_train_)\n",
    "        validate_ = model_default.score(X_val_, y_val_)\n",
    "\n",
    "        if validate_accuracy < validate_:\n",
    "\n",
    "            validate_accuracy = validate_\n",
    "            train_accuracy = model_default.score(X_train_, y_train_)\n",
    "            y_pred = model_default.predict(X_test)\n",
    "            test_accuracy = model_default.score(X_test, y_test)\n",
    "            joblib.dump(model_default,  model_out, compress=9)\n",
    "            index = idx+1\n",
    "\n",
    "    print(f\"Cross validaion {index}\")\n",
    "    print(\"Validation Accuracy:\",'%.3f' % validate_accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d574dc0faab36e82a60f408c766093e49e340e14dd7ea017c130825f7bc8d85"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pangolin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

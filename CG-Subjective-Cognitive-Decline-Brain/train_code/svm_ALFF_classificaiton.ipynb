{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CPU count: {}\".format(multiprocessing.cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type ='mat' #mat, csv, mix\n",
    "# dataloader\n",
    "clinical_data = pd.read_csv('./data/clinical data/clinical_data_2.csv')[['subj', 'AD8主觀認知障礙[0-1,>=2]', 'MOCA客觀認知測驗分數[<=23,>=24]', 'HADS_A焦慮程度', 'HADS_D憂鬱程度']]\n",
    "raw_data_path = './data/mdALFF matrix excel/' #raw_data_path = './data/image data/dFC matrix matlab/'\n",
    "next_path ='mdALFF_var.csv' # mdALFF_var.csv #next_path ='C0005FC_z.mat't'\n",
    "def loader_(data_path = None, data_type='mat' ,mat_dtype='FCM_mean'):\n",
    "    if '.mat' in data_path:\n",
    "        mat = scipy.io.loadmat(data_path)\n",
    "        get_value = mat[mat_dtype ]\n",
    "        return get_value.shape\n",
    "\n",
    "    else:\n",
    "        pd_tb = pd.read_csv(data_path)\n",
    "        pd_patient_index = pd_tb[pd_tb.columns[0]]\n",
    "        pd_patient_value = pd_tb[pd_tb.columns[1::]]\n",
    "        return pd_patient_index, pd_patient_value\n",
    "_, patient_value = loader_(data_path = os.path.join(raw_data_path,next_path))\n",
    "patient_value_index = clinical_data['subj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model list\n",
    "def model_list(grid=False, seed=123):\n",
    "    # svr_param = {'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),'C' : [1,5,10],'degree' : [3,8],'coef0' : [0.01,10,0.5],'gamma' : ('auto','scale')}\n",
    "    # SVR_ = SVR()\n",
    "    \n",
    "    xgbr_param = {'nthread':[4], 'objective':['reg:squarederror'], 'learning_rate': [.03, 0.05, .07], 'max_depth': [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31], 'min_child_weight': [4], \n",
    "                                    'subsample': [0.7], 'colsample_bytree': [0.7], 'n_estimators': [400, 450, 500, 550, 600, 660]}\n",
    "    XGBR_ =XGBClassifier(random_state = seed,learning_rate = 0.1, max_depth = 5, min_child_weight = 1, \n",
    "                        subsample = 0.6, colsample_bytree = 0.8, gamma = 0, reg_alhpa = 0, reg_lambda = 1,verbosity=0, verbose = -1, n_estimators=100)\n",
    "    \n",
    "    # lgbmr_param =  {'num_leaves': [7, 14, 21], 'learning_rate': [0.05, 0.005], 'max_depth': [10, 15, 25], \n",
    "    #                                     'min_data_in_leaf':[10, 15, 25], 'feature_fraction': [0.6, 0.8, 0.9],'cat_smooth': [1,10, 15, 20, 35], 'verbose': [-1]}\n",
    "    lgbmr_param =  {'learning_rate': [0.01, 0.05, 0.001,0.005], 'max_depth': [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31], 'verbose': [-1]}\n",
    "    \n",
    "    \n",
    "    LGBMR_ = LGBMClassifier(random_state=seed, verbose = -1)\n",
    "\n",
    "    mlpr_param =  {'hidden_layer_sizes': [(25), (50), (100)]}\n",
    "\n",
    "\n",
    "    # mlpr_param =  {'hidden_layer_sizes': [(25), (50), (75),(100), (25, 50), (50,100), (25, 50, 75),(50, 75, 100)], 'learning_rate_init': [0.01, 0.03, 0.001, 0.003, 0.0001, 0.0003],\n",
    "    #                                     'activation': ['relu', 'tanh'], 'solver': ['adam', 'lbfgs'], 'learning_rate' : ['constant', 'adaptive', 'invscaling']}\n",
    "\n",
    "    MLPR_ = MLPClassifier(activation = 'relu', solver = 'adam', max_iter=20000, random_state=seed, early_stopping=False, verbose=1)\n",
    "    \n",
    "    if grid ==True:\n",
    "        # model_stack = {\"SVR\":[SVR_, svr_param], \"XBGR\":[XGBR_, xgbr_param], \"LGBMR\": [LGBMR_, lgbmr_param]}\n",
    "        model_stack = {\"MLPR\":[MLPR_, mlpr_param], \"XBGR\":[XGBR_, xgbr_param], \"LGBMR\": [LGBMR_, lgbmr_param]}\n",
    "        # model_stack = {\"XBGR\":[XGBR_, xgbr_param], \"LGBMR\": [LGBMR_, lgbmr_param]}\n",
    "    else:\n",
    "        # model_stack = {\"SVR\":SVR_, \"XBGR\":XGBR_, \"LGBMR\": LGBMR_}\n",
    "        # model_stack = {\"XBGR\":XGBR_, \"LGBMR\": LGBMR_}\n",
    "        model_stack = {\"MLPR\":MLPR_, \"XBGR\":XGBR_, \"LGBMR\": LGBMR_}\n",
    "    return model_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = False\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "if True:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fxn()\n",
    "        # classification : AD8 [0-1, >=2]{0,1}, MOCA [<=23, >=24]{0,1}\n",
    "        # outcome_name = 'MOCA客觀認知測驗分數[<=23,>=24]' #AD8主觀認知障礙[0-1,>=2], MOCA客觀認知測驗分數[<=23,>=24]\n",
    "        model_stack = model_list(grid=grid)\n",
    "        kfold = KFold(n_splits=4)\n",
    "        for outcome_name in [\"MOCA客觀認知測驗分數[<=23,>=24]\"]:\n",
    "            for model in model_stack:\n",
    "                if model in ['MLPR', 'XBGR', 'LGBMR']:\n",
    "                    if grid==False:\n",
    "                        label_ = clinical_data[outcome_name]\n",
    "                        print(\"Outcome: {}\".format(outcome_name))\n",
    "                        print(\"--Start Training {} model--\".format(model))\n",
    "                        if 'MOCA' in outcome_name:\n",
    "                            label_s = [1 if (i>=24)  else 0  for i in list(label_)]\n",
    "                        elif 'AD8' in outcome_name:\n",
    "                            label_s = [1 if i>=2 else 0 for i in list(label_)]\n",
    "                            label_ = label_+1\n",
    "                        X_train, X_test, y_train, y_test   = train_test_split(patient_value, label_s , stratify=list(label_s), random_state=123)\n",
    "                        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, stratify=list(y_train), test_size=0.50, random_state=123)\n",
    "                        if model in 'MLPR':\n",
    "                            model = model_stack[model].fit(X_train, y_train)\n",
    "                        else:\n",
    "                            \n",
    "                            model = model_stack[model].fit(np.array(X_train), np.array(y_train))\n",
    "                        train_pred =  model.predict(X_train)\n",
    "                        \n",
    "                        test_pred =  model.predict(X_valid)\n",
    "                    else:\n",
    "                        GridModel = GridSearchCV(model_stack[model][0],model_stack[model][1], cv=kfold, n_jobs=-1, verbose=-1, refit = 'neg_mean_squared_error', scoring=['neg_mean_squared_error','neg_mean_absolute_percentage_error'],\n",
    "                                                 return_train_score=True)\n",
    "                        GridModel = GridSearchCV(model_stack[model][0],model_stack[model][1], cv=kfold, n_jobs=-1, verbose=-1, refit = 'neg_mean_absolute_percentage_error', scoring=\"neg_mean_absolute_percentage_error\",\n",
    "                                                 return_train_score=True)\n",
    "                        GridModel.fit(np.array(X_train).astype(np.float16), np.array(y_train).astype(np.int8))\n",
    "                        param_grid = model_stack[model][1]\n",
    "                        print(\"Grid Metric\", GridModel.cv_results_.keys())\n",
    "                        for res_ in GridModel.cv_results_:\n",
    "                            if 'test_score' in res_:\n",
    "                                print(res_,GridModel.cv_results_[res_])\n",
    "                        print(\"Scoring\", GridModel.best_score_)\n",
    "                        print('Best parameter : [{}]\\n'.format(GridModel.best_params_))\n",
    "                        train_pred =  GridModel.predict(X_train)\n",
    "                        test_pred =  GridModel.predict(X_test)\n",
    "                        print(\"Data Length. Training : {} || Validation: {}\".format(len(y_train), len(y_valid)))\n",
    "                        model_stack[model].fit(X_train, y_train, verbose=0)\n",
    "                        val_pred =  model_stack[model].predict(X_valid)\n",
    "                        train_pred =  model_stack[model].predict(X_train)\n",
    "\n",
    "                    print('Train Accuracy: ', round(metrics.balanced_accuracy_score(y_train,train_pred), 5))\n",
    "                    print('Valid Accuracy: ', round(metrics.balanced_accuracy_score(y_valid,test_pred), 5))\n",
    "                    print('----------------------------------------------------')\n",
    "                print('\\n')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([-0.76256473, -0.92615425, -1.04265153])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('SCD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "450185acc0ada52b3ee7083194a106bdbcbbdc01a8d098f62c0a2148c7a4fe8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8d922c8450>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, torch, os, sys, multiprocessing, pandas as pd\n",
    "import torch.backends.cudnn as cudnn, torchio as tio, random\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from sklearn.metrics import *\n",
    "sys.path.append(\"..\")\n",
    "from utils.model_res import generate_model\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm   \n",
    "\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv label\n",
    "if True:\n",
    "    csv_path = '../20211104_label_1-350_1.5&3.0.csv'\n",
    "    table_3t =  pd.read_csv(csv_path)\n",
    "    # table_3t = table[table['1/0: 3T/1.5T MRI']==1.0]\n",
    "    table_3t_test = table_3t[table_3t['Valid data']=='V']\n",
    "    table_3t_test = np.array(table_3t_test[table_3t_test['排除']=='Test data'])\n",
    "    nii_3t_test = sorted([i for i in os.listdir(os.path.join('../dataset/S2_data1.5&3.0/','test'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject Function Building\n",
    "def tio_process(nii_3t_, table_3t_, basepath_='../dataset/S2_data/train/'):\n",
    "    subjects_ = []\n",
    "    for  (nii_path, nii_table) in zip(nii_3t_ , table_3t_):\n",
    "        # print(nii_path)\n",
    "        if (params['S2_type']=='ap') and (nii_table[3]=='A' or nii_table[3]=='P'):\n",
    "            subject = tio.Subject(\n",
    "                dwi = tio.ScalarImage(os.path.join(basepath_, nii_path)), \n",
    "                msk = tio.ScalarImage(os.path.join('../dataset/S2_data1.5&3.0/test_mask/', nii_path)), \n",
    "                ap = nii_table[3], \n",
    "                score=[])\n",
    "            subjects_.append(subject)\n",
    "        elif (params['S2_type']=='nl'):\n",
    "            subject = tio.Subject(\n",
    "                dwi = tio.ScalarImage(os.path.join(basepath_, nii_path)), \n",
    "                msk = tio.ScalarImage(os.path.join('../dataset/S2_data1.5&3.0/test_mask/', nii_path)), \n",
    "                nl  = nii_table[4], \n",
    "                score=[])\n",
    "            subjects_.append(subject)\n",
    "    return subjects_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]/home/john/anaconda3/envs/torch-SGD/lib/python3.8/site-packages/torchio/transforms/preprocessing/spatial/resize.py:64: UserWarning: Output shape (384, 384, 29) != target shape (384, 384, 28). Fixing with CropOrPad\n",
      "  warnings.warn(message)\n",
      "/home/john/anaconda3/envs/torch-SGD/lib/python3.8/site-packages/torchio/transforms/preprocessing/spatial/resize.py:64: UserWarning: Output shape (384, 384, 29) != target shape (384, 384, 28). Fixing with CropOrPad\n",
      "  warnings.warn(message)\n",
      " 85%|████████▌ | 68/80 [00:24<00:04,  2.44it/s]/home/john/anaconda3/envs/torch-SGD/lib/python3.8/site-packages/torchio/transforms/preprocessing/spatial/resize.py:64: UserWarning: Output shape (384, 384, 29) != target shape (384, 384, 28). Fixing with CropOrPad\n",
      "  warnings.warn(message)\n",
      "100%|██████████| 80/80 [00:29<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def S1_evaluate(model, valid_loader):\n",
    "    predict_array = []\n",
    "    ground_array = []\n",
    "    model.eval()\n",
    "    stream = tqdm(valid_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, images in enumerate(stream, start=1):\n",
    "            try:\n",
    "                img = images['dwi'][tio.DATA]\n",
    "                msk = images['msk'][tio.DATA]\n",
    "            except:\n",
    "                print(images['dwi']['path'], images['msk']['path'])\n",
    "            # torch.Size([1, 1, 384, 384, 26])\n",
    "            img = img.squeeze(0)\n",
    "            msk = msk.squeeze(0)\n",
    "            img = img.permute(3,0,1,2)\n",
    "            msk = msk.permute(3,0,1,2)\n",
    "            img = img.to(device)\n",
    "            msk = msk.to(device)\n",
    "            output =  model(img)\n",
    "            if False:\n",
    "                print(images['dwi']['path'])\n",
    "                for idx in range(26):\n",
    "                    fig = plt.figure()\n",
    "                    \n",
    "                    ax1 = fig.add_subplot(1,3,1)\n",
    "                    ax1.imshow(np.squeeze(img[idx], axis=0), cmap='bone')\n",
    "                    ax1.set_title(\"Ground Truth\")\n",
    "                    ax1.get_xaxis().set_visible(False)\n",
    "                    ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "                    ax2 = fig.add_subplot(1,3,2)\n",
    "                    ax2.imshow(np.squeeze(msk[idx]>0.05, axis=0), cmap='bone')\n",
    "                    ax2.set_title(\"Raw Masks\")\n",
    "                    ax2.get_xaxis().set_visible(False)\n",
    "                    ax2.get_yaxis().set_visible(False)\n",
    "                    \n",
    "                    ax3 = fig.add_subplot(1,3,3)\n",
    "                    ax3.imshow(np.squeeze(output[idx]>0.1, axis=0), cmap='bone')\n",
    "                    ax3.set_title(\"Predict Masks\")\n",
    "                    ax3.get_xaxis().set_visible(False)\n",
    "                    ax3.get_yaxis().set_visible(False)\n",
    "                    plt.show()\n",
    "                    plt.close(fig)\n",
    "            \n",
    "            predict_array.append(output)\n",
    "            ground_array.append(msk)\n",
    "    return predict_array, ground_array\n",
    "\n",
    "def change_subject_img(subject_, tesnor_ary):\n",
    "    for idx, i in enumerate(subject_):\n",
    "        if False:\n",
    "            print( subject_[idx]['dwi'].shape)\n",
    "            for idx2 in range(26):\n",
    "                fig = plt.figure(figsize=(12,12))\n",
    "                ax1 = fig.add_subplot(1,3,1)\n",
    "                ax1.imshow(np.squeeze((subject_[idx]['dwi'][tio.DATA])[...,idx2], axis=0), cmap='bone')\n",
    "                ax1.get_xaxis().set_visible(False)\n",
    "                ax1.get_yaxis().set_visible(False)\n",
    "                ax2 = fig.add_subplot(1,3,2)\n",
    "                ax2.imshow(np.squeeze((tesnor_ary[idx])[...,idx2], axis=0), cmap='bone')\n",
    "                ax2.get_xaxis().set_visible(False)\n",
    "                ax2.get_yaxis().set_visible(False)\n",
    "                plt.show()\n",
    "                plt.close(fig)\n",
    "        subject_[idx]['dwi'].set_data(tesnor_ary[idx])\n",
    "        # image =  subject_[idx]['dwi'][tio.DATA]\n",
    "    return subject_\n",
    "\n",
    "def label2value(label):\n",
    "    if params[\"S2_type\"]=='nl':\n",
    "        target = [0 if i=='N' else 1 for i in label]\n",
    "    else:\n",
    "        target = [0 if i=='A' else 1 for i in label]\n",
    "    return torch.LongTensor(target).to(device)\n",
    "\n",
    "if True:\n",
    "    test_transform = tio.Compose([tio.Resize((384,384,28))])\n",
    "    S1_weight = '../checkpoint/2021.11.23.t2 - 2DDenseNet121Unet/2DDenseNet121Unet - lr_0.001 - FTL --  epoch:105 | vDice:0.7908 | vLoss:0.0634.pt'\n",
    "    S1_checkpoint = torch.load(S1_weight, map_location=torch.device(device))\n",
    "    S1_model = smp.Unet(encoder_name='densenet121', encoder_weights=None, in_channels=1, classes=1)\n",
    "    S1_model.load_state_dict(S1_checkpoint['model_state_dict'])\n",
    "    S1_model.to(device)\n",
    "for idx, i in enumerate(['nl']):\n",
    "    params = {\"S1_type\": None, \"S2_type\": i}\n",
    "    S1_subjects = tio_process(nii_3t_test, table_3t_test, basepath_ = '../dataset/S2_data1.5&3.0/test/')\n",
    "    S1_set = tio.SubjectsDataset(S1_subjects, transform=test_transform)\n",
    "    test_loader = torch.utils.data.DataLoader(S1_set, batch_size=1, shuffle=False, num_workers=6)\n",
    "    S1_reply, S1_ans = S1_evaluate(S1_model, test_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class avg_metric:\n",
    "        def __init__(self):\n",
    "            self.dice_sum = 0.0\n",
    "            self.iou_sum = 0.0\n",
    "            self.sens_sum = 0.0\n",
    "            self.spec_sum =0.0\n",
    "        def metric_calc(self, batch_inputs, batch_targets):\n",
    "                smooth = 1\n",
    "                # print(batch_inputs)\n",
    "                # print(inputs.max(), inputs.min())\n",
    "                # print(batch_inputs.shape)\n",
    "                inputs = torch.sigmoid(batch_inputs)\n",
    "                inputs = (inputs - inputs.min()) / (inputs.max() - inputs.min() + 1e-8) #****!!!!\n",
    "                inputs = (inputs.contiguous().view(-1))\n",
    "                \n",
    "                targets = batch_targets.contiguous().view(-1)\n",
    "                # print(inputs.shape, targets.shape)\n",
    "                intersection = (inputs * targets).sum()\n",
    "                total = (inputs + targets).sum()\n",
    "                union = total - intersection \n",
    "                TP = int(intersection) #TP\n",
    "                FN = int((targets * (1-inputs)).sum()) #FN\n",
    "                TN = int(((1-targets) * (1-inputs)).sum()) #TN\n",
    "                FP = int(((1-targets) * inputs).sum()) #FP\n",
    "                # print(dice)\n",
    "                \n",
    "                # print(TP,FN,TN,FP)\n",
    "                self.dice_sum += ((2.*intersection+ smooth)/(inputs.sum() + targets.sum()+ smooth)).item()\n",
    "                self.iou_sum +=((intersection+ smooth)/(union+ smooth)).item()\n",
    "                self.sens_sum+= round(float(TP)/(float(TP+FN)), 5)\n",
    "                self.spec_sum += round(float(TN)/(float(TN+FP)), 5)\n",
    "        def return_metric(self, len):\n",
    "                return {'Dice': round(self.dice_sum/len, 5) , \n",
    "                                'IoU':round(self.iou_sum/len, 5) , \n",
    "                                'Sensitivity': round(self.sens_sum/len, 5) , \n",
    "                                'Specificity': round(self.spec_sum/len, 5) , }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dice': 0.69767, 'IoU': 0.56971, 'Sensitivity': 0.69947, 'Specificity': 0.9998}\n"
     ]
    }
   ],
   "source": [
    "metric_class = avg_metric()\n",
    "for (inputs, targets) in zip(S1_reply, S1_ans):\n",
    "    metric_class.metric_calc(inputs, targets)\n",
    "print(metric_class.return_metric(len(S1_reply)))\n",
    "# ---------------- 3.0T + 1.5T ----------------\n",
    "# {'Dice': 0.69767, 'IoU': 0.56971, 'Sensitivity': 0.69947, 'Specificity': 0.9998}\n",
    "\n",
    "# ---------------- 3.0T -------------------------\n",
    "# {'Dice': 0.6992, 'IoU': 0.56704, 'Sensitivity': 0.75734, 'Specificity': 0.9997} 0.2\n",
    "# {'Dice': 0.68367, 'IoU': 0.55184, 'Sensitivity': 0.73547, 'Specificity': 0.99978} 0.2\n",
    "# {'Dice': 0.60646, 'IoU': 0.48663, 'Sensitivity': 0.54321, 'Specificity': 0.9999} 0.0001\n",
    "# {'Dice': 0.59049, 'IoU': 0.46844, 'Sensitivity': 0.50486, 'Specificity': 0.99993} 0.1\n",
    "# {'Dice': 0.58312, 'IoU': 0.46012, 'Sensitivity': 0.49119, 'Specificity': 0.99994} 0.5\n",
    "# {'Dice': 0.57463, 'IoU': 0.45072, 'Sensitivity': 0.47765, 'Specificity': 0.99994} 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx2 in range(26):\n",
    "#     fig = plt.figure(figsize=(12,12))\n",
    "#     ax1 = fig.add_subplot(1,3,1)\n",
    "#     print(max(S1_reply[0][idx2].flatten()), min(S1_reply[0][idx2].flatten()))\n",
    "#     ax1.imshow(np.squeeze(S1_reply[0][idx2], axis=0), cmap='bone')\n",
    "#     ax1.get_xaxis().set_visible(False)\n",
    "#     ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "#     plt.show()\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7173b66b0b7b9d3ef17108453430ecf43b59c5f40b531d440cd8bb0e5f91238"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('torch-SGD': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
